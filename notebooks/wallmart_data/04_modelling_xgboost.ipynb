{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee802ed-e405-4f86-985a-c6e0656c5265",
   "metadata": {},
   "source": [
    "# Part IV: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dffd0-604c-4434-9f56-9f67578d60a2",
   "metadata": {},
   "source": [
    "## Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a20043-c34e-41ec-a61f-d10c46238fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bae6ca2-7d52-4ed1-90e0-bf5dcb510dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Asus\\App\\miniconda\\workspace\\envs\\sales_forcast_xai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fefc9dd-198a-4604-9ba3-c96566203eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = os.path.abspath(os.path.join(\"../..\", \"src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f3a359-c913-4b1b-8329-3a7a3c8c982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_forecast_single\n",
    "from utils.utils import flatten_prophet_predictions, weighted_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10499f54-a5e2-47e2-9460-daaeca91675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature data: (686187, 89)\n",
      "Kaggle test rows: 526917\n",
      "Train rows: 159270\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"../../data\"\n",
    "\n",
    "# 1. LOAD DATA ĐÃ PREPROCESS VÀ FEATURE ENGINEERING\n",
    "df_sales = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"data_processed/sales_data_preprocessed.csv\"),\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "df_weather = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"data_processed/weather_preprocessed.csv\"),\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "# df_weather_key_store_merged = pd.read_csv(\n",
    "#     os.path.join(DATA_DIR, \"data_processed/weather_key_store_merged.csv\"),\n",
    "#     parse_dates=[\"date\"]\n",
    "# )\n",
    "\n",
    "# Đây là file đã có is_kaggle_test và toàn bộ features\n",
    "df_features = pd.read_feather(os.path.join(DATA_DIR,'data_processed/feature_engineered_data_89_features.feather'))\n",
    "\n",
    "print(\"Full feature data:\", df_features.shape)\n",
    "print(\"Kaggle test rows:\", df_features['is_kaggle_test'].sum())\n",
    "print(\"Train rows:\", (df_features['is_kaggle_test'] == 0).sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12747917-837a-4b8a-9fc2-502deb096ea5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6afa0d-32fe-4192-b89c-00b7d9cf11e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final splits:\n",
      "  Train: (153496, 90)\n",
      "  Valid: (5774, 90)\n",
      "  Kaggle test: (526917, 90)\n"
     ]
    }
   ],
   "source": [
    "df_features['is_valid'] = 0\n",
    "mask_train = df_features['is_kaggle_test'] == 0\n",
    "cutoff_date = pd.Timestamp(\"2014-08-01\")\n",
    "df_features.loc[mask_train & (df_features['date'] >= cutoff_date), 'is_valid'] = 1\n",
    "\n",
    "# 2. Tách train/valid và kaggle test\n",
    "df_train = df_features[(df_features['is_kaggle_test'] == 0) & (df_features['is_valid'] == 0)].copy()\n",
    "df_valid = df_features[(df_features['is_kaggle_test'] == 0) & (df_features['is_valid'] == 1)].copy()\n",
    "df_kaggle_test = df_features[df_features['is_kaggle_test'] == 1].copy()\n",
    "\n",
    "print(\"Final splits:\")\n",
    "print(\"  Train:\", df_train.shape)\n",
    "print(\"  Valid:\", df_valid.shape)\n",
    "print(\"  Kaggle test:\", df_kaggle_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b12af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>logunits</th>\n",
       "      <th>is_kaggle_test</th>\n",
       "      <th>station_nbr</th>\n",
       "      <th>tmax</th>\n",
       "      <th>depart</th>\n",
       "      <th>cool</th>\n",
       "      <th>...</th>\n",
       "      <th>logunits_ewma_14d_a05</th>\n",
       "      <th>logunits_ewma_28d_a05</th>\n",
       "      <th>logunits_ewma_7d_a075</th>\n",
       "      <th>logunits_ewma_14d_a075</th>\n",
       "      <th>logunits_ewma_28d_a075</th>\n",
       "      <th>store_sum_7d</th>\n",
       "      <th>store_mean_7d</th>\n",
       "      <th>item_sum_7d</th>\n",
       "      <th>item_mean_7d</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159270</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.670772</td>\n",
       "      <td>1.238682</td>\n",
       "      <td>7.203406</td>\n",
       "      <td>1.029058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159271</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.825560</td>\n",
       "      <td>1.260794</td>\n",
       "      <td>6.510258</td>\n",
       "      <td>1.085043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159272</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.102488</td>\n",
       "      <td>1.728927</td>\n",
       "      <td>5.817111</td>\n",
       "      <td>1.163422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159273</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.648221</td>\n",
       "      <td>1.235460</td>\n",
       "      <td>5.123964</td>\n",
       "      <td>1.280991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159274</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.572480</td>\n",
       "      <td>1.367497</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>1.059351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  store_nbr  item_nbr  units  logunits  is_kaggle_test  \\\n",
       "159270 2013-04-01          2         1    NaN       NaN            True   \n",
       "159271 2013-04-01          3         1    NaN       NaN            True   \n",
       "159272 2013-04-01          6         1    NaN       NaN            True   \n",
       "159273 2013-04-01          7         1    NaN       NaN            True   \n",
       "159274 2013-04-01          8         1    NaN       NaN            True   \n",
       "\n",
       "        station_nbr  tmax  depart  cool  ...  logunits_ewma_14d_a05  \\\n",
       "159270           14  71.0     1.0   0.0  ...                    NaN   \n",
       "159271            7  68.0     6.2   0.0  ...                    NaN   \n",
       "159272           14  71.0     1.0   0.0  ...                    NaN   \n",
       "159273            6  86.0     6.0   5.0  ...                    NaN   \n",
       "159274            4  87.0     8.0   9.0  ...                    NaN   \n",
       "\n",
       "        logunits_ewma_28d_a05  logunits_ewma_7d_a075  logunits_ewma_14d_a075  \\\n",
       "159270                    NaN                    NaN                     NaN   \n",
       "159271                    NaN                    NaN                     NaN   \n",
       "159272                    NaN                    NaN                     NaN   \n",
       "159273                    NaN                    NaN                     NaN   \n",
       "159274                    NaN                    NaN                     NaN   \n",
       "\n",
       "        logunits_ewma_28d_a075  store_sum_7d  store_mean_7d  item_sum_7d  \\\n",
       "159270                     NaN      8.670772       1.238682     7.203406   \n",
       "159271                     NaN      8.825560       1.260794     6.510258   \n",
       "159272                     NaN     12.102488       1.728927     5.817111   \n",
       "159273                     NaN      8.648221       1.235460     5.123964   \n",
       "159274                     NaN      9.572480       1.367497     3.178054   \n",
       "\n",
       "        item_mean_7d  is_valid  \n",
       "159270      1.029058         0  \n",
       "159271      1.085043         0  \n",
       "159272      1.163422         0  \n",
       "159273      1.280991         0  \n",
       "159274      1.059351         0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e5c03b-dfdb-4bdf-81e9-b811b98e50d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 153496 entries, 0 to 159249\n",
      "Data columns (total 90 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   date                    153496 non-null  datetime64[ns]\n",
      " 1   store_nbr               153496 non-null  int64         \n",
      " 2   item_nbr                153496 non-null  int64         \n",
      " 3   units                   153496 non-null  float64       \n",
      " 4   logunits                153496 non-null  float64       \n",
      " 5   is_kaggle_test          153496 non-null  bool          \n",
      " 6   station_nbr             153496 non-null  int64         \n",
      " 7   tmax                    153496 non-null  float64       \n",
      " 8   depart                  153496 non-null  float64       \n",
      " 9   cool                    153496 non-null  float64       \n",
      " 10  sunrise                 153496 non-null  float64       \n",
      " 11  sunset                  153496 non-null  float64       \n",
      " 12  snowfall                153496 non-null  float64       \n",
      " 13  preciptotal             153496 non-null  float64       \n",
      " 14  stnpressure             153496 non-null  float64       \n",
      " 15  sealevel                153496 non-null  float64       \n",
      " 16  resultspeed             153496 non-null  float64       \n",
      " 17  resultdir               153496 non-null  float64       \n",
      " 18  BCFG                    153496 non-null  int64         \n",
      " 19  BLDU                    153496 non-null  int64         \n",
      " 20  BLSN                    153496 non-null  int64         \n",
      " 21  BR                      153496 non-null  int64         \n",
      " 22  DU                      153496 non-null  int64         \n",
      " 23  DZ                      153496 non-null  int64         \n",
      " 24  FG                      153496 non-null  int64         \n",
      " 25  FG+                     153496 non-null  int64         \n",
      " 26  FU                      153496 non-null  int64         \n",
      " 27  FZDZ                    153496 non-null  int64         \n",
      " 28  FZFG                    153496 non-null  int64         \n",
      " 29  FZRA                    153496 non-null  int64         \n",
      " 30  GR                      153496 non-null  int64         \n",
      " 31  GS                      153496 non-null  int64         \n",
      " 32  HZ                      153496 non-null  int64         \n",
      " 33  MIFG                    153496 non-null  int64         \n",
      " 34  PL                      153496 non-null  int64         \n",
      " 35  PRFG                    153496 non-null  int64         \n",
      " 36  RA                      153496 non-null  int64         \n",
      " 37  SG                      153496 non-null  int64         \n",
      " 38  SN                      153496 non-null  int64         \n",
      " 39  SQ                      153496 non-null  int64         \n",
      " 40  TS                      153496 non-null  int64         \n",
      " 41  TSRA                    153496 non-null  int64         \n",
      " 42  TSSN                    153496 non-null  int64         \n",
      " 43  UP                      153496 non-null  int64         \n",
      " 44  VCFG                    153496 non-null  int64         \n",
      " 45  VCTS                    153496 non-null  int64         \n",
      " 46  year                    153496 non-null  int32         \n",
      " 47  month                   153496 non-null  int32         \n",
      " 48  day                     153496 non-null  int32         \n",
      " 49  day_of_week             153496 non-null  int32         \n",
      " 50  is_weekend              153496 non-null  int64         \n",
      " 51  season                  153496 non-null  int64         \n",
      " 52  season_Spring           153496 non-null  int64         \n",
      " 53  season_Summer           153496 non-null  int64         \n",
      " 54  season_Winter           153496 non-null  int64         \n",
      " 55  is_holiday              153496 non-null  int64         \n",
      " 56  is_blackfriday          153496 non-null  int64         \n",
      " 57  logunits_lag_1          153496 non-null  float64       \n",
      " 58  logunits_lag_2          153496 non-null  float64       \n",
      " 59  logunits_lag_3          153496 non-null  float64       \n",
      " 60  logunits_lag_4          153496 non-null  float64       \n",
      " 61  logunits_lag_5          153496 non-null  float64       \n",
      " 62  logunits_lag_6          153496 non-null  float64       \n",
      " 63  logunits_lag_7          153496 non-null  float64       \n",
      " 64  logunits_lag_14         153496 non-null  float64       \n",
      " 65  logunits_lag_21         153496 non-null  float64       \n",
      " 66  logunits_lag_28         153496 non-null  float64       \n",
      " 67  logunits_mean_7d        153496 non-null  float64       \n",
      " 68  logunits_min_7d         153496 non-null  float64       \n",
      " 69  logunits_max_7d         153496 non-null  float64       \n",
      " 70  logunits_std_7d         153496 non-null  float64       \n",
      " 71  logunits_mean_14d       153496 non-null  float64       \n",
      " 72  logunits_min_14d        153496 non-null  float64       \n",
      " 73  logunits_max_14d        153496 non-null  float64       \n",
      " 74  logunits_std_14d        153496 non-null  float64       \n",
      " 75  logunits_mean_28d       153496 non-null  float64       \n",
      " 76  logunits_min_28d        153496 non-null  float64       \n",
      " 77  logunits_max_28d        153496 non-null  float64       \n",
      " 78  logunits_std_28d        153496 non-null  float64       \n",
      " 79  logunits_ewma_7d_a05    153496 non-null  float64       \n",
      " 80  logunits_ewma_14d_a05   153496 non-null  float64       \n",
      " 81  logunits_ewma_28d_a05   153496 non-null  float64       \n",
      " 82  logunits_ewma_7d_a075   153496 non-null  float64       \n",
      " 83  logunits_ewma_14d_a075  153496 non-null  float64       \n",
      " 84  logunits_ewma_28d_a075  153496 non-null  float64       \n",
      " 85  store_sum_7d            153496 non-null  float64       \n",
      " 86  store_mean_7d           153496 non-null  float64       \n",
      " 87  item_sum_7d             153496 non-null  float64       \n",
      " 88  item_mean_7d            153496 non-null  float64       \n",
      " 89  is_valid                153496 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), float64(45), int32(4), int64(39)\n",
      "memory usage: 103.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630715f-21ce-4859-8325-6f3c8956058b",
   "metadata": {},
   "source": [
    "## Build xboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2063b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    'date', 'units', 'logunits',\n",
    "    'is_kaggle_test', 'is_valid',\n",
    "    'store_nbr', 'item_nbr', 'station_nbr',\n",
    "    'tmax', 'depart', 'cool', 'sunrise', 'sunset',\n",
    "    'snowfall', 'preciptotal', 'stnpressure', 'sealevel',\n",
    "    'resultspeed', 'resultdir',\n",
    "    'BCFG', 'BLDU', 'BLSN', 'BR', 'DU', 'DZ', 'FG', 'FG+',\n",
    "    'FU', 'FZDZ', 'FZFG', 'FZRA', 'GR', 'GS', 'HZ', 'MIFG',\n",
    "    'PL', 'PRFG', 'RA', 'SG', 'SN', 'SQ', 'TS', 'TSRA',\n",
    "    'TSSN', 'UP', 'VCFG', 'VCTS'\n",
    "]\n",
    "\n",
    "feature_cols = [c for c in df_features.columns if c not in drop_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3bdc1-c273-4ee0-8f7f-923897e4cf84",
   "metadata": {},
   "source": [
    "### Build a lightgbm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea66f23-83e6-45d6-90d0-dd262986d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xgboost_model(df_train, df_valid, feature_cols):\n",
    "    \"\"\"\n",
    "    Building XGBoost models per (store, item) pair with optimized parameters\n",
    "    \"\"\"\n",
    "    print(\"Building XGBoost models per (store, item)...\")\n",
    "\n",
    "    pairs = df_train[['store_nbr', 'item_nbr']].drop_duplicates()\n",
    "\n",
    "    xgb_models = {}\n",
    "    xgb_metrics = []\n",
    "    all_actual, all_pred = [], []\n",
    "\n",
    "    for _, row in pairs.iterrows():\n",
    "        s, i = int(row['store_nbr']), int(row['item_nbr'])\n",
    "\n",
    "        train_si = df_train[(df_train['store_nbr'] == s) &\n",
    "                            (df_train['item_nbr'] == i)]\n",
    "        valid_si = df_valid[(df_valid['store_nbr'] == s) &\n",
    "                            (df_valid['item_nbr'] == i)]\n",
    "\n",
    "        # Không đủ dữ liệu thì bỏ\n",
    "        if len(train_si) < 20:\n",
    "            continue\n",
    "\n",
    "        X_tr = train_si[feature_cols]\n",
    "        y_tr = train_si['logunits']\n",
    "        X_va = valid_si[feature_cols]\n",
    "        y_va = valid_si['logunits']\n",
    "\n",
    "        # Sử dụng tham số tối ưu từ Optuna\n",
    "        params = {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"verbosity\": 0,\n",
    "            \"max_depth\": 7,\n",
    "            \"learning_rate\": 0.010113217909182654,\n",
    "            \"subsample\": 0.7997828501729438,\n",
    "            \"colsample_bytree\": 0.5574819523335883,\n",
    "            \"colsample_bylevel\": 0.6808836497575912,\n",
    "            \"min_child_weight\": 10,\n",
    "            \"gamma\": 0.19820345140994988,\n",
    "            \"reg_alpha\": 5.277969035526557e-06,\n",
    "            \"reg_lambda\": 1.3028132129165083e-07,\n",
    "        }\n",
    "\n",
    "        # Prepare DMatrix\n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        \n",
    "        # Train với early stopping nếu có validation set\n",
    "        if not valid_si.empty:\n",
    "            dvalid = xgb.DMatrix(X_va, label=y_va)\n",
    "            model = xgb.train(\n",
    "                params,\n",
    "                dtrain,\n",
    "                num_boost_round=2000,\n",
    "                evals=[(dvalid, \"validation\")],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "        else:\n",
    "            model = xgb.train(\n",
    "                params,\n",
    "                dtrain,\n",
    "                num_boost_round=2000,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "\n",
    "        key = (s, i)\n",
    "        xgb_models[key] = model\n",
    "\n",
    "        if not valid_si.empty:\n",
    "            dvalid_pred = xgb.DMatrix(X_va)\n",
    "            preds = model.predict(dvalid_pred)\n",
    "            mae = mean_absolute_error(y_va, preds)\n",
    "            rmse = np.sqrt(mean_squared_error(y_va, preds))\n",
    "            wape = weighted_absolute_percentage_error(y_va, preds)\n",
    "            xgb_metrics.append((s, i, mae, rmse, wape))\n",
    "            all_actual.extend(y_va)\n",
    "            all_pred.extend(preds)\n",
    "\n",
    "    if xgb_metrics:\n",
    "        mae_avg = np.mean([m[2] for m in xgb_metrics])\n",
    "        rmse_avg = np.mean([m[3] for m in xgb_metrics])\n",
    "        wape_avg = weighted_absolute_percentage_error(\n",
    "            np.array(all_actual), np.array(all_pred)\n",
    "        )\n",
    "        print(f\"\\nOverall XGBoost per-(store,item) valid metrics:\")\n",
    "        print(f\"MAE: {mae_avg:.4f} | RMSE: {rmse_avg:.4f} | WAPE: {wape_avg:.4f}\")\n",
    "\n",
    "    print(\"Models built:\", len(xgb_models))\n",
    "    return xgb_models, xgb_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52819f7-c5fa-43b4-99b5-01dc13a5e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building XGBoost models per (store, item)...\n",
      "\n",
      "Overall XGBoost per-(store,item) valid metrics:\n",
      "MAE: 0.2337 | RMSE: 0.2933 | WAPE: 15.9816\n",
      "Models built: 255\n"
     ]
    }
   ],
   "source": [
    "xgb_models, xgb_metrics = create_xgboost_model(\n",
    "    df_train, df_valid, feature_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff1382e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved submission_xgb_per_store_item.csv (526917 rows)\n"
     ]
    }
   ],
   "source": [
    "def create_xgboost_submission(\n",
    "    df_kaggle_test, xgb_models, feature_cols,\n",
    "    filename=\"submission_xgb_per_store_item.csv\"\n",
    "):\n",
    "    \n",
    "    df_kaggle = df_kaggle_test.copy()\n",
    "    kaggle_parts = []\n",
    "\n",
    "    pairs_test = df_kaggle[['store_nbr', 'item_nbr']].drop_duplicates()\n",
    "\n",
    "    for _, row in pairs_test.iterrows():\n",
    "        s, i = int(row['store_nbr']), int(row['item_nbr'])\n",
    "        key = (s, i)\n",
    "\n",
    "        test_si = df_kaggle[\n",
    "            (df_kaggle[\"store_nbr\"] == s) &\n",
    "            (df_kaggle[\"item_nbr\"] == i)\n",
    "        ].copy()\n",
    "        if test_si.empty:\n",
    "            continue\n",
    "\n",
    "        X_test_si = test_si[feature_cols]\n",
    "\n",
    "        if key in xgb_models:\n",
    "            # XGBoost cần DMatrix để predict\n",
    "            dtest = xgb.DMatrix(X_test_si)\n",
    "            yhat_log = xgb_models[key].predict(dtest)\n",
    "            units = np.expm1(yhat_log)\n",
    "            units = np.clip(units, 0, None)\n",
    "        else:\n",
    "            units = np.zeros(len(test_si))\n",
    "\n",
    "        test_si[\"units\"] = units\n",
    "        kaggle_parts.append(test_si)\n",
    "\n",
    "    if not kaggle_parts:\n",
    "        raise ValueError(\"Không có dòng nào được dự đoán.\")\n",
    "\n",
    "    df_kaggle_pred = pd.concat(kaggle_parts, ignore_index=True)\n",
    "\n",
    "    df_kaggle_pred[\"date_str\"] = df_kaggle_pred[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    df_kaggle_pred = df_kaggle_pred.sort_values([\"date_str\", \"store_nbr\", \"item_nbr\"])\n",
    "\n",
    "    df_kaggle_pred[\"id\"] = (\n",
    "        df_kaggle_pred[\"store_nbr\"].astype(str) + \"_\" +\n",
    "        df_kaggle_pred[\"item_nbr\"].astype(str) + \"_\" +\n",
    "        df_kaggle_pred[\"date_str\"]\n",
    "    )\n",
    "\n",
    "    submission = df_kaggle_pred[[\"id\", \"units\"]].reset_index(drop=True)\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"✓ Saved {filename} ({len(submission)} rows)\")\n",
    "    return submission\n",
    "\n",
    "submission = create_xgboost_submission(\n",
    "    df_kaggle_test, xgb_models, feature_cols,\n",
    "    filename=\"submission_xgb_per_store_item.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69bc79b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng dòng có dự đoán bán hàng: 25684\n",
      "Ví dụ 5 dòng có số liệu:\n",
      "                 id       units\n",
      "4    2_5_2013-04-01   64.529587\n",
      "10  2_11_2013-04-01    0.977494\n",
      "43  2_44_2013-04-01  178.603058\n",
      "84  2_85_2013-04-01    0.016873\n",
      "92  2_93_2013-04-01    0.077276\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra nhanh: Đếm số lượng dòng dự đoán khác 0\n",
    "non_zero_preds = submission[submission['units'] > 0]\n",
    "print(f\"Số lượng dòng có dự đoán bán hàng: {len(non_zero_preds)}\")\n",
    "print(\"Ví dụ 5 dòng có số liệu:\")\n",
    "print(non_zero_preds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8bad5-ddbd-4091-ba03-5bcfbe412736",
   "metadata": {},
   "source": [
    "### (Optional) Fine tunning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91197807-9c05-43ad-bcd0-4040f913a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgboost(X_train, y_train, X_valid, y_valid, n_trials=50):\n",
    "    print(\"\\nOptimizing XGBoost model with Optuna...\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        # Hyperparameters search space for XGBoost\n",
    "        params = {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"verbosity\": 0,\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "            \"n_estimators\": 2000,\n",
    "        }\n",
    "        \n",
    "        # Prepare DMatrix\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "        \n",
    "        # Train with early stopping\n",
    "        evals_result = {}\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=2000,\n",
    "            evals=[(dvalid, \"validation\")],\n",
    "            evals_result=evals_result,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        # Predict và tính metric mục tiêu (WAPE)\n",
    "        dvalid_pred = xgb.DMatrix(X_valid)\n",
    "        preds = model.predict(dvalid_pred)\n",
    "        # wape = weighted_absolute_percentage_error(y_valid, preds)\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "        return rmse  # Optimize trực tiếp WAPE\n",
    "    \n",
    "    # Chạy Optuna\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"\\nBest params found:\")\n",
    "    best_params = study.best_params\n",
    "    best_params.update({\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"verbosity\": 0,\n",
    "        \"n_estimators\": 2000\n",
    "    })\n",
    "    \n",
    "    for k, v in best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    \n",
    "    # Train final model với best params\n",
    "    dtrain_final = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid_final = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    \n",
    "    evals_result_final = {}\n",
    "    final_model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain_final,\n",
    "        num_boost_round=2000,\n",
    "        evals=[(dvalid_final, \"validation\")],\n",
    "        evals_result=evals_result_final,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "\n",
    "    dvalid_pred = xgb.DMatrix(X_valid)\n",
    "    valid_preds = final_model.predict(dvalid_pred)\n",
    "    test_mae = mean_absolute_error(y_valid, valid_preds)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_valid, valid_preds))\n",
    "    test_wape = weighted_absolute_percentage_error(y_valid, valid_preds)\n",
    "    \n",
    "    print(f\"\\nOptimized XGBoost Valid Metrics - MAE: {test_mae:.3f}, RMSE: {test_rmse:.3f}, WAPE: {test_wape:.3f}\")\n",
    "    \n",
    "    return final_model, best_params, (test_mae, test_rmse, test_wape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a39ebd4d-bf01-4e6a-9976-e9574eb7767c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 04:23:57,870] A new study created in memory with name: no-name-88b9b745-c4fc-43f7-8bc6-00a1f26b879f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing XGBoost model with Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 04:24:08,016] Trial 0 finished with value: 0.36189861059052447 and parameters: {'max_depth': 7, 'learning_rate': 0.02017264434054835, 'subsample': 0.6239811888590259, 'colsample_bytree': 0.9549488498433473, 'colsample_bylevel': 0.6865894304709103, 'min_child_weight': 4, 'gamma': 0.5619609314352109, 'reg_alpha': 3.022616652731097e-06, 'reg_lambda': 3.36444740730876e-07}. Best is trial 0 with value: 0.36189861059052447.\n",
      "[I 2025-11-29 04:24:11,946] Trial 1 finished with value: 0.36106731614377136 and parameters: {'max_depth': 8, 'learning_rate': 0.06891046469929286, 'subsample': 0.7219350229051826, 'colsample_bytree': 0.6926040548892449, 'colsample_bylevel': 0.5240938570767197, 'min_child_weight': 4, 'gamma': 0.7373671768059187, 'reg_alpha': 1.4979158695888615e-08, 'reg_lambda': 0.0005264408443746626}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:24:18,510] Trial 2 finished with value: 0.3636285512508863 and parameters: {'max_depth': 4, 'learning_rate': 0.021518536777324817, 'subsample': 0.5814579493880934, 'colsample_bytree': 0.5212185452563707, 'colsample_bylevel': 0.5408350532236165, 'min_child_weight': 7, 'gamma': 1.4253719139026022, 'reg_alpha': 0.575724619727251, 'reg_lambda': 4.138125057075963e-07}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:24:24,214] Trial 3 finished with value: 0.367100167677907 and parameters: {'max_depth': 3, 'learning_rate': 0.0915341949135481, 'subsample': 0.9507129670149052, 'colsample_bytree': 0.8627232510982925, 'colsample_bylevel': 0.580316642550462, 'min_child_weight': 8, 'gamma': 2.087211068101672, 'reg_alpha': 0.054070225733803566, 'reg_lambda': 0.0024835988251704676}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:24:26,012] Trial 4 finished with value: 0.36523043365366636 and parameters: {'max_depth': 3, 'learning_rate': 0.0338847987344397, 'subsample': 0.9854752438892418, 'colsample_bytree': 0.7254441310814298, 'colsample_bylevel': 0.516806100772379, 'min_child_weight': 4, 'gamma': 1.3285944518166932, 'reg_alpha': 1.2630585465331817e-07, 'reg_lambda': 1.1677132354132571}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:24:38,188] Trial 5 finished with value: 0.36305641435649777 and parameters: {'max_depth': 4, 'learning_rate': 0.04341527125711691, 'subsample': 0.8522015090780889, 'colsample_bytree': 0.7772630206170694, 'colsample_bylevel': 0.9080525998499103, 'min_child_weight': 9, 'gamma': 1.130179143814497, 'reg_alpha': 0.4216639494986897, 'reg_lambda': 0.00018307857001667398}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:24:47,891] Trial 6 finished with value: 0.36225443170847604 and parameters: {'max_depth': 5, 'learning_rate': 0.01167892653007314, 'subsample': 0.6222943912369903, 'colsample_bytree': 0.6343105898305341, 'colsample_bylevel': 0.9684334738644369, 'min_child_weight': 9, 'gamma': 0.5998672084599593, 'reg_alpha': 8.812121193048359, 'reg_lambda': 6.171535274198069e-05}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:07,161] Trial 7 finished with value: 0.36167483615117996 and parameters: {'max_depth': 10, 'learning_rate': 0.012417056050886608, 'subsample': 0.5171539055766087, 'colsample_bytree': 0.7906033133505864, 'colsample_bylevel': 0.765487880929363, 'min_child_weight': 1, 'gamma': 1.8688302865366517, 'reg_alpha': 0.11753095499738656, 'reg_lambda': 0.0005707426884752777}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:08,791] Trial 8 finished with value: 0.3643065775540587 and parameters: {'max_depth': 9, 'learning_rate': 0.07168748303195617, 'subsample': 0.6657020295225645, 'colsample_bytree': 0.7385720531831992, 'colsample_bylevel': 0.9141116622638001, 'min_child_weight': 6, 'gamma': 3.780744778158516, 'reg_alpha': 6.51210143431895e-07, 'reg_lambda': 0.43977076739418614}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:11,274] Trial 9 finished with value: 0.3628862066458591 and parameters: {'max_depth': 10, 'learning_rate': 0.07116295401651282, 'subsample': 0.8831310622101168, 'colsample_bytree': 0.5462112042595273, 'colsample_bylevel': 0.5783549996672548, 'min_child_weight': 4, 'gamma': 4.357241239545772, 'reg_alpha': 1.3641712977920417e-08, 'reg_lambda': 1.3687110624171747e-08}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:11,839] Trial 10 finished with value: 0.3679865018588725 and parameters: {'max_depth': 8, 'learning_rate': 0.24649518383015326, 'subsample': 0.7520884197650487, 'colsample_bytree': 0.6466679650477021, 'colsample_bylevel': 0.7075803934272605, 'min_child_weight': 1, 'gamma': 3.1032110979218883, 'reg_alpha': 0.000985584545256459, 'reg_lambda': 0.027882216926295125}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:17,872] Trial 11 finished with value: 0.37218514793831214 and parameters: {'max_depth': 10, 'learning_rate': 0.1677679208331054, 'subsample': 0.5212707299231578, 'colsample_bytree': 0.8622586281366318, 'colsample_bylevel': 0.7975893614635216, 'min_child_weight': 1, 'gamma': 2.3984385967831594, 'reg_alpha': 0.00045496986352113876, 'reg_lambda': 2.2375438663375896e-05}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:18,980] Trial 12 finished with value: 0.36680837893244705 and parameters: {'max_depth': 8, 'learning_rate': 0.11963886623575726, 'subsample': 0.7486865110765044, 'colsample_bytree': 0.8397075358196634, 'colsample_bylevel': 0.813521726192741, 'min_child_weight': 2, 'gamma': 0.08793967511428713, 'reg_alpha': 5.6233554553074395e-05, 'reg_lambda': 0.0024736129528642615}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:26,419] Trial 13 finished with value: 0.3623012012003678 and parameters: {'max_depth': 6, 'learning_rate': 0.013007342657413682, 'subsample': 0.7177686068276826, 'colsample_bytree': 0.6519560764265452, 'colsample_bylevel': 0.6484629750312314, 'min_child_weight': 3, 'gamma': 1.8744938142276095, 'reg_alpha': 0.008979025899916357, 'reg_lambda': 0.012368295680934721}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:27,941] Trial 14 finished with value: 0.3649446817044384 and parameters: {'max_depth': 9, 'learning_rate': 0.03256218825758625, 'subsample': 0.532026557429276, 'colsample_bytree': 0.9735769764664262, 'colsample_bylevel': 0.7862085247209183, 'min_child_weight': 5, 'gamma': 2.8741596027351446, 'reg_alpha': 1.3081985059515505e-05, 'reg_lambda': 3.798716743120022e-06}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:37,172] Trial 15 finished with value: 0.36292308781479216 and parameters: {'max_depth': 8, 'learning_rate': 0.04711182927584598, 'subsample': 0.8210783670467476, 'colsample_bytree': 0.8034968200294066, 'colsample_bylevel': 0.6250352225763878, 'min_child_weight': 2, 'gamma': 0.10243581591753004, 'reg_alpha': 0.006126745857734363, 'reg_lambda': 0.09463064390920431}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:40,779] Trial 16 finished with value: 0.36189331597331925 and parameters: {'max_depth': 9, 'learning_rate': 0.020789529250484967, 'subsample': 0.5072824943090625, 'colsample_bytree': 0.6947050581983812, 'colsample_bylevel': 0.7285058276587553, 'min_child_weight': 6, 'gamma': 1.7087230582136879, 'reg_alpha': 4.8733836080672255, 'reg_lambda': 0.0008772590196888713}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:41,714] Trial 17 finished with value: 0.36334519849581376 and parameters: {'max_depth': 7, 'learning_rate': 0.12636815104726062, 'subsample': 0.6879715323423787, 'colsample_bytree': 0.5827140367943469, 'colsample_bylevel': 0.8540396835476523, 'min_child_weight': 3, 'gamma': 0.8639518670598756, 'reg_alpha': 3.30260112588165e-08, 'reg_lambda': 6.743894259649808e-06}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:42,251] Trial 18 finished with value: 0.36422203166382905 and parameters: {'max_depth': 10, 'learning_rate': 0.24999281836401702, 'subsample': 0.7730929629380783, 'colsample_bytree': 0.8986816196721013, 'colsample_bylevel': 0.762127762245807, 'min_child_weight': 2, 'gamma': 3.3077586009560913, 'reg_alpha': 0.00010214024004209602, 'reg_lambda': 8.829063467862342}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:42,897] Trial 19 finished with value: 0.36447333178869107 and parameters: {'max_depth': 6, 'learning_rate': 0.06378545168353382, 'subsample': 0.5769848337289362, 'colsample_bytree': 0.6973923694881479, 'colsample_bylevel': 0.6512286067468198, 'min_child_weight': 5, 'gamma': 4.965976933598654, 'reg_alpha': 0.055970267096025234, 'reg_lambda': 0.00048261840160734014}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:47,372] Trial 20 finished with value: 0.36228747411807494 and parameters: {'max_depth': 9, 'learning_rate': 0.015625269575741473, 'subsample': 0.9226893098392135, 'colsample_bytree': 0.7849475147866856, 'colsample_bylevel': 0.5956456920558617, 'min_child_weight': 10, 'gamma': 2.5440459475966817, 'reg_alpha': 7.36818436819119e-07, 'reg_lambda': 0.009627634158027164}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:25:53,686] Trial 21 finished with value: 0.36299994978808814 and parameters: {'max_depth': 9, 'learning_rate': 0.02298155931086129, 'subsample': 0.5140055719511838, 'colsample_bytree': 0.6957518805809099, 'colsample_bylevel': 0.7382818825474996, 'min_child_weight': 6, 'gamma': 1.845063961352754, 'reg_alpha': 6.5399929748556564, 'reg_lambda': 0.0005026484388458695}. Best is trial 1 with value: 0.36106731614377136.\n",
      "[I 2025-11-29 04:26:07,376] Trial 22 finished with value: 0.3609500679987302 and parameters: {'max_depth': 8, 'learning_rate': 0.010381341368466203, 'subsample': 0.5654357329763227, 'colsample_bytree': 0.5983186567227929, 'colsample_bylevel': 0.7092385203856926, 'min_child_weight': 7, 'gamma': 1.5089667944163068, 'reg_alpha': 0.6967120987748694, 'reg_lambda': 0.0019839589245294704}. Best is trial 22 with value: 0.3609500679987302.\n",
      "[I 2025-11-29 04:26:18,435] Trial 23 finished with value: 0.3610865439780825 and parameters: {'max_depth': 7, 'learning_rate': 0.010409710337068074, 'subsample': 0.572156935854761, 'colsample_bytree': 0.5760890774779315, 'colsample_bylevel': 0.8342753485542387, 'min_child_weight': 7, 'gamma': 0.952330514613078, 'reg_alpha': 0.5821801091095904, 'reg_lambda': 4.0309438754188366e-05}. Best is trial 22 with value: 0.3609500679987302.\n",
      "[I 2025-11-29 04:26:21,138] Trial 24 finished with value: 0.3621600968189898 and parameters: {'max_depth': 7, 'learning_rate': 0.03291452009026151, 'subsample': 0.5785137288587627, 'colsample_bytree': 0.5956924867260587, 'colsample_bylevel': 0.850968361368102, 'min_child_weight': 7, 'gamma': 0.9096788110432308, 'reg_alpha': 0.7854341858484928, 'reg_lambda': 4.670997639105742e-05}. Best is trial 22 with value: 0.3609500679987302.\n",
      "[I 2025-11-29 04:26:29,065] Trial 25 finished with value: 0.36090364289476273 and parameters: {'max_depth': 8, 'learning_rate': 0.010582775991567317, 'subsample': 0.638798318882211, 'colsample_bytree': 0.5789218067116002, 'colsample_bylevel': 0.8378496567652649, 'min_child_weight': 7, 'gamma': 0.47183914375549585, 'reg_alpha': 0.004416805793205088, 'reg_lambda': 1.436444104042068e-06}. Best is trial 25 with value: 0.36090364289476273.\n",
      "[I 2025-11-29 04:26:33,518] Trial 26 finished with value: 0.3617084905804367 and parameters: {'max_depth': 8, 'learning_rate': 0.015925000221030244, 'subsample': 0.644432285543324, 'colsample_bytree': 0.6139958472438702, 'colsample_bylevel': 0.8822624819021585, 'min_child_weight': 8, 'gamma': 0.5434701552770547, 'reg_alpha': 0.0032284265472761805, 'reg_lambda': 1.4578485402594777e-06}. Best is trial 25 with value: 0.36090364289476273.\n",
      "[I 2025-11-29 04:26:49,522] Trial 27 finished with value: 0.362176267644488 and parameters: {'max_depth': 8, 'learning_rate': 0.02799742522508591, 'subsample': 0.6924816270071539, 'colsample_bytree': 0.5127769476676898, 'colsample_bylevel': 0.9774172869128588, 'min_child_weight': 8, 'gamma': 0.23433667504225036, 'reg_alpha': 0.017465690832323015, 'reg_lambda': 6.498246577489225e-08}. Best is trial 25 with value: 0.36090364289476273.\n",
      "[I 2025-11-29 04:26:53,461] Trial 28 finished with value: 0.36191864659731854 and parameters: {'max_depth': 6, 'learning_rate': 0.015025868786447252, 'subsample': 0.6303352963340726, 'colsample_bytree': 0.5449286337842509, 'colsample_bylevel': 0.5062893443610859, 'min_child_weight': 5, 'gamma': 1.447701924878685, 'reg_alpha': 6.15407250876741e-05, 'reg_lambda': 0.07862711718672205}. Best is trial 25 with value: 0.36090364289476273.\n",
      "[I 2025-11-29 04:27:01,611] Trial 29 finished with value: 0.36051116042915277 and parameters: {'max_depth': 7, 'learning_rate': 0.043928246723229834, 'subsample': 0.717300222324533, 'colsample_bytree': 0.5561714798828157, 'colsample_bylevel': 0.6957362791074463, 'min_child_weight': 7, 'gamma': 0.5509848405915139, 'reg_alpha': 8.111039980993931e-06, 'reg_lambda': 2.8393172777992543e-07}. Best is trial 29 with value: 0.36051116042915277.\n",
      "[I 2025-11-29 04:27:10,731] Trial 30 finished with value: 0.360583586670352 and parameters: {'max_depth': 7, 'learning_rate': 0.017426255320765117, 'subsample': 0.8015519501384234, 'colsample_bytree': 0.559877592885193, 'colsample_bylevel': 0.6656680235236636, 'min_child_weight': 9, 'gamma': 0.42855937141468825, 'reg_alpha': 1.7919021275278565e-05, 'reg_lambda': 1.2863312667468945e-07}. Best is trial 29 with value: 0.36051116042915277.\n",
      "[I 2025-11-29 04:27:28,990] Trial 31 finished with value: 0.36010414961511555 and parameters: {'max_depth': 7, 'learning_rate': 0.010113217909182654, 'subsample': 0.7997828501729438, 'colsample_bytree': 0.5574819523335883, 'colsample_bylevel': 0.6808836497575912, 'min_child_weight': 10, 'gamma': 0.19820345140994988, 'reg_alpha': 5.277969035526557e-06, 'reg_lambda': 1.3028132129165083e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:32,481] Trial 32 finished with value: 0.3615110827295185 and parameters: {'max_depth': 6, 'learning_rate': 0.01729069300709355, 'subsample': 0.8136501719281475, 'colsample_bytree': 0.5508701722816278, 'colsample_bylevel': 0.6788362310253185, 'min_child_weight': 10, 'gamma': 0.34327873293044253, 'reg_alpha': 4.534056171888033e-06, 'reg_lambda': 1.0815546923204066e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:35,789] Trial 33 finished with value: 0.3608686921831401 and parameters: {'max_depth': 7, 'learning_rate': 0.025267893791094117, 'subsample': 0.7990594584081654, 'colsample_bytree': 0.5217051679466962, 'colsample_bylevel': 0.6634458313685703, 'min_child_weight': 9, 'gamma': 0.5434655001097171, 'reg_alpha': 6.5071161436849385e-06, 'reg_lambda': 5.241734488675651e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:37,839] Trial 34 finished with value: 0.36265856700587695 and parameters: {'max_depth': 5, 'learning_rate': 0.026096364775680506, 'subsample': 0.7966872281693371, 'colsample_bytree': 0.5117689303459828, 'colsample_bylevel': 0.6526172929790994, 'min_child_weight': 9, 'gamma': 0.5878663469199801, 'reg_alpha': 1.3555230646405253e-05, 'reg_lambda': 1.730684435601688e-08}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:39,562] Trial 35 finished with value: 0.3611316113260363 and parameters: {'max_depth': 7, 'learning_rate': 0.04291913451496032, 'subsample': 0.8408994535842195, 'colsample_bytree': 0.5007533740305239, 'colsample_bylevel': 0.6782498875229932, 'min_child_weight': 10, 'gamma': 0.033878858842813275, 'reg_alpha': 7.953640485184467e-07, 'reg_lambda': 2.753865011391505e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:41,370] Trial 36 finished with value: 0.36268526807310747 and parameters: {'max_depth': 5, 'learning_rate': 0.018896053871136877, 'subsample': 0.8843199168348851, 'colsample_bytree': 0.5475909450531545, 'colsample_bylevel': 0.5563908990178188, 'min_child_weight': 9, 'gamma': 1.2085098125022053, 'reg_alpha': 3.196375013494642e-06, 'reg_lambda': 5.5959562136568325e-08}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:42,816] Trial 37 finished with value: 0.36095129493835687 and parameters: {'max_depth': 7, 'learning_rate': 0.026211412569495683, 'subsample': 0.7798043014026685, 'colsample_bytree': 0.6613856643560989, 'colsample_bylevel': 0.6056628357851601, 'min_child_weight': 8, 'gamma': 1.0979964790821093, 'reg_alpha': 1.2177316479348074e-05, 'reg_lambda': 4.4778806814666026e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:44,185] Trial 38 finished with value: 0.3607899183040892 and parameters: {'max_depth': 7, 'learning_rate': 0.05137413602319086, 'subsample': 0.7341953480115262, 'colsample_bytree': 0.6237857115440775, 'colsample_bylevel': 0.6970066633243479, 'min_child_weight': 10, 'gamma': 0.8074768306990286, 'reg_alpha': 2.0948689921545824e-07, 'reg_lambda': 2.6531141519981754e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:48,060] Trial 39 finished with value: 0.36347064780491223 and parameters: {'max_depth': 6, 'learning_rate': 0.05421248933897862, 'subsample': 0.7209148731494476, 'colsample_bytree': 0.6180987177577864, 'colsample_bylevel': 0.7100321720719599, 'min_child_weight': 10, 'gamma': 0.74503834862075, 'reg_alpha': 1.50714867223664e-07, 'reg_lambda': 3.789223977144246e-08}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:27:51,510] Trial 40 finished with value: 0.36471387497990104 and parameters: {'max_depth': 4, 'learning_rate': 0.09838296731734686, 'subsample': 0.7531161306553, 'colsample_bytree': 0.563533644027751, 'colsample_bylevel': 0.6275546400505452, 'min_child_weight': 10, 'gamma': 0.30197266186265526, 'reg_alpha': 1.3379604601583912e-07, 'reg_lambda': 1.6731343512836917e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:00,142] Trial 41 finished with value: 0.36020872159364586 and parameters: {'max_depth': 7, 'learning_rate': 0.03797308591985428, 'subsample': 0.8523695018136632, 'colsample_bytree': 0.5263861676968551, 'colsample_bylevel': 0.6846290237141537, 'min_child_weight': 9, 'gamma': 0.7150320452722488, 'reg_alpha': 1.0816568222682585e-06, 'reg_lambda': 8.461371416148248e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:04,656] Trial 42 finished with value: 0.3611572262240888 and parameters: {'max_depth': 7, 'learning_rate': 0.03883566285988669, 'subsample': 0.8627762447241638, 'colsample_bytree': 0.6196407318495714, 'colsample_bylevel': 0.6884056356902079, 'min_child_weight': 9, 'gamma': 0.7956736789649492, 'reg_alpha': 4.695954252629683e-07, 'reg_lambda': 1.557900516196102e-06}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:05,395] Trial 43 finished with value: 0.3622494835546126 and parameters: {'max_depth': 6, 'learning_rate': 0.05571327943790459, 'subsample': 0.9386527016499728, 'colsample_bytree': 0.5282533005900875, 'colsample_bylevel': 0.7343679188273942, 'min_child_weight': 8, 'gamma': 1.1135654667984356, 'reg_alpha': 1.1326130156918002e-06, 'reg_lambda': 1.034127575092992e-08}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:11,403] Trial 44 finished with value: 0.36111907546614347 and parameters: {'max_depth': 7, 'learning_rate': 0.07860019964514668, 'subsample': 0.9012135026197813, 'colsample_bytree': 0.6718318664477485, 'colsample_bylevel': 0.6256131765282532, 'min_child_weight': 9, 'gamma': 0.3543638963573416, 'reg_alpha': 5.7006160178901014e-08, 'reg_lambda': 7.335306240988269e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:17,143] Trial 45 finished with value: 0.361555703623351 and parameters: {'max_depth': 7, 'learning_rate': 0.038210282497286946, 'subsample': 0.8443916136321553, 'colsample_bytree': 0.5599743364560817, 'colsample_bylevel': 0.6949116844513868, 'min_child_weight': 10, 'gamma': 0.026539456684653295, 'reg_alpha': 1.8986767022890918e-06, 'reg_lambda': 5.961908352022739e-06}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:19,337] Trial 46 finished with value: 0.36225010798208856 and parameters: {'max_depth': 6, 'learning_rate': 0.012790133880557374, 'subsample': 0.7346029919580165, 'colsample_bytree': 0.526900459911108, 'colsample_bylevel': 0.7559642384297408, 'min_child_weight': 9, 'gamma': 2.1893716808307775, 'reg_alpha': 3.1684838338639154e-07, 'reg_lambda': 1.4748170644038227e-07}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:22,773] Trial 47 finished with value: 0.36409275989182255 and parameters: {'max_depth': 5, 'learning_rate': 0.05156908753576299, 'subsample': 0.9725899043399766, 'colsample_bytree': 0.6329839476899818, 'colsample_bylevel': 0.7161887268070068, 'min_child_weight': 8, 'gamma': 1.3309251567463676, 'reg_alpha': 2.3136316627723457e-05, 'reg_lambda': 2.4966302247465378e-08}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:24,330] Trial 48 finished with value: 0.36147017539062826 and parameters: {'max_depth': 8, 'learning_rate': 0.06167471128145864, 'subsample': 0.696020335861336, 'colsample_bytree': 0.5988957494863292, 'colsample_bylevel': 0.6721526067161963, 'min_child_weight': 10, 'gamma': 0.6211263162871989, 'reg_alpha': 0.00029377900397031467, 'reg_lambda': 1.0897447265334853e-05}. Best is trial 31 with value: 0.36010414961511555.\n",
      "[I 2025-11-29 04:28:28,454] Trial 49 finished with value: 0.36264644076059466 and parameters: {'max_depth': 7, 'learning_rate': 0.08280228829201734, 'subsample': 0.7718513650376858, 'colsample_bytree': 0.5351878129674599, 'colsample_bylevel': 0.7787090184076905, 'min_child_weight': 9, 'gamma': 1.6433754268820775, 'reg_alpha': 1.9390010612736047e-06, 'reg_lambda': 3.0901104873594904e-06}. Best is trial 31 with value: 0.36010414961511555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params found:\n",
      "  max_depth: 7\n",
      "  learning_rate: 0.010113217909182654\n",
      "  subsample: 0.7997828501729438\n",
      "  colsample_bytree: 0.5574819523335883\n",
      "  colsample_bylevel: 0.6808836497575912\n",
      "  min_child_weight: 10\n",
      "  gamma: 0.19820345140994988\n",
      "  reg_alpha: 5.277969035526557e-06\n",
      "  reg_lambda: 1.3028132129165083e-07\n",
      "  objective: reg:squarederror\n",
      "  eval_metric: rmse\n",
      "  verbosity: 0\n",
      "  n_estimators: 2000\n",
      "[0]\tvalidation-rmse:1.71359\n",
      "[100]\tvalidation-rmse:0.70899\n",
      "[200]\tvalidation-rmse:0.42783\n",
      "[300]\tvalidation-rmse:0.37335\n",
      "[400]\tvalidation-rmse:0.36416\n",
      "[500]\tvalidation-rmse:0.36209\n",
      "[600]\tvalidation-rmse:0.36133\n",
      "[700]\tvalidation-rmse:0.36095\n",
      "[800]\tvalidation-rmse:0.36075\n",
      "[900]\tvalidation-rmse:0.36059\n",
      "[1000]\tvalidation-rmse:0.36046\n",
      "[1100]\tvalidation-rmse:0.36041\n",
      "[1200]\tvalidation-rmse:0.36040\n",
      "[1300]\tvalidation-rmse:0.36023\n",
      "[1400]\tvalidation-rmse:0.36014\n",
      "[1500]\tvalidation-rmse:0.36019\n",
      "[1529]\tvalidation-rmse:0.36010\n",
      "\n",
      "Optimized XGBoost Valid Metrics - MAE: 0.200, RMSE: 0.360, WAPE: 14.663\n"
     ]
    }
   ],
   "source": [
    "optimized_model, best_params, optimized_metrics = optimize_xgboost(\n",
    "    X_train, y_train, X_valid, y_valid, n_trials=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "970ed2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved submission_xgboost_optim.csv (526917 rows)\n"
     ]
    }
   ],
   "source": [
    "submission = create_xgboost_submission(df_kaggle_test, optimized_model, filename=\"submission_xgboost_optim.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dcb0bd-8977-4f88-88bf-3678ec5ab50b",
   "metadata": {},
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7306f426-a791-4612-9348-d3b4ed663e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, data):\n",
    "    \"\"\"\n",
    "    Evaluate the model performance on the test set (last 3 months of 2017)\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluating model performance on test set...\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_mae = mean_absolute_error(y_test, test_preds)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    test_wape = weighted_absolute_percentage_error(y_test, test_preds)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Final Model Test Evaluation:\")\n",
    "    print(f\"    MAE: {test_mae:.2f}\")\n",
    "    print(f\"    RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"    WAPE: {test_wape:.2f}%\")\n",
    "\n",
    "    # Analyze errors by time period (month)\n",
    "    test_results = data[data[\"is_test\"]].copy()\n",
    "    test_results[\"prediction\"] = test_preds\n",
    "    test_results[\"error\"] = test_results[\"sales\"] - test_results[\"prediction\"]\n",
    "    test_results[\"abs_error\"] = np.abs(test_results[\"error\"])\n",
    "    test_results[\"month_name\"] = test_results[\"date\"].dt.strftime(\"%B\")\n",
    "\n",
    "    # Summarize errors by month\n",
    "    monthly_errors = (\n",
    "        test_results.groupby(\"month_name\")\n",
    "        .agg({\"abs_error\": \"mean\", \"error\": \"mean\", \"sales\": \"mean\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    monthly_errors[\"error_pct\"] = (\n",
    "        100 * monthly_errors[\"abs_error\"] / monthly_errors[\"sales\"]\n",
    "    )\n",
    "\n",
    "    print(\"\\nError Analysis by Month:\")\n",
    "    print(\n",
    "        monthly_errors[[\"month_name\", \"abs_error\", \"error_pct\"]].to_string(index=False)\n",
    "    )\n",
    "\n",
    "    # Store results for visualization\n",
    "    # Include month and store information for granular analysis\n",
    "    test_results[\"year_month\"] = test_results[\"date\"].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, test_preds, alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], \"r--\")\n",
    "    plt.title(\"Actual vs Predicted Sales (Test Set)\")\n",
    "    plt.xlabel(\"Actual Sales\")\n",
    "    plt.ylabel(\"Predicted Sales\")\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('actual_vs_predicted_test.png')\n",
    "\n",
    "    # Plot error distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(test_results[\"error\"], kde=True)\n",
    "    plt.title(\"Error Distribution\")\n",
    "    plt.xlabel(\"Prediction Error\")\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('error_distribution.png')\n",
    "\n",
    "    return test_mae, test_rmse, test_wape, test_preds, y_test, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b19bcf0-9d6a-4218-bba3-129fada6026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet Model Results:\n",
    "# MAE: 9.03 | RMSE: 11.86 | WAPE: 29.13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acbf2b3c-f81b-4746-90cc-8c4a8088a268",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lightgbm_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the lightgbm model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m test_mae, test_rmse, test_smape, test_preds, y_test_values, test_results \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 3\u001b[0m     evaluate_model(\u001b[43mlightgbm_model\u001b[49m, X_test, y_test, df_features)\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lightgbm_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the lightgbm model\n",
    "test_mae, test_rmse, test_smape, test_preds, y_test_values, test_results = (\n",
    "    evaluate_model(lightgbm_model, X_test, y_test, df_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e343dda-bec5-4525-91cc-a81ac25229d0",
   "metadata": {},
   "source": [
    "## Save trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8505cb-07cb-4175-9e04-5b4674befac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, X_train, feature_names, output_dir=\"../models\"):\n",
    "    \"\"\"\n",
    "    Save the trained model and related artifacts for API use\n",
    "\n",
    "    Args:\n",
    "        model: Trained model (e.g., LightGBM model)\n",
    "        feature_names: List of feature names\n",
    "        output_dir: Directory to save model artifacts\n",
    "    \"\"\"\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = os.path.join(output_dir, \"sales_forecast_model.pkl\")\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Create and save feature statistics\n",
    "    feature_stats = {\n",
    "        \"model_version\": \"1.0.0\",\n",
    "        \"last_trained\": pd.Timestamp.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"required_columns\": list(feature_names),\n",
    "        \"column_order\": list(feature_names),\n",
    "        \"default_values\": {},\n",
    "        \"temperature_bins\": [-np.inf, 20, 25, 30, np.inf],\n",
    "        \"temperature_labels\": [\"Cold\", \"Cool\", \"Warm\", \"Hot\"],\n",
    "        \"humidity_bins\": [-np.inf, 60, 75, np.inf],\n",
    "        \"humidity_labels\": [\"Low\", \"Medium\", \"High\"],\n",
    "    }\n",
    "\n",
    "    # Add default values for date features\n",
    "    feature_stats[\"default_values\"] = {\n",
    "        \"year\": 2017,\n",
    "        \"month\": 11,\n",
    "        \"day\": 15,\n",
    "        \"day_of_week\": 2,\n",
    "        \"is_weekend\": 0,\n",
    "        \"quarter\": 4,\n",
    "        \"is_holiday\": 0,\n",
    "    }\n",
    "\n",
    "    # Save feature stats\n",
    "    stats_path = os.path.join(output_dir, \"feature_stats.json\")\n",
    "    with open(stats_path, \"w\") as f:\n",
    "        json.dump(feature_stats, f, indent=4)\n",
    "    print(f\"Feature statistics saved to {stats_path}\")\n",
    "\n",
    "    print(f\"All model artifacts saved successfully to {output_dir}/\")\n",
    "\n",
    "    return model_path, stats_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2cd1b-6d74-435c-be7c-d0ac999020d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/sales_forecast_model.pkl\n",
      "Feature statistics saved to ../models/feature_stats.json\n",
      "All model artifacts saved successfully to ../models/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/sales_forecast_model.pkl', '../models/feature_stats.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "save_model(\n",
    "    model=optimized_model,\n",
    "    X_train=X_train,\n",
    "    feature_names=X_train.columns,\n",
    "    output_dir='../models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5cc83-1c5b-4ab3-83af-cd3a6c3f00fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales_forcast_xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
