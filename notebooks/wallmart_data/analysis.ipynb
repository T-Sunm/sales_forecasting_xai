{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Overview ]\n",
    "\n",
    "### (1) Objective : \n",
    "> #### 20 지역에서 관측한 날씨에 따른, 월마트 매장 45곳에서 판매하는 111가지 품목의 판매량( `units` )을 예측한다.\n",
    "\n",
    "### (2) Data : \n",
    "> #### train : 4617600 rows, 4 columns  \n",
    "> - 2012년 1월 1일 ~ 2014년 10월 31일 사이 월마트 매장 45곳에서 판매하는 111가지 품목의 판매량 데이터  \n",
    "\n",
    "> #### test : 526917 rows, 3 columns\n",
    "> - 2013년 4월 1일 ~ 2014년 10월 26일 사이 월마트 매장 44곳 (35번 매장 누락) 에 대한 템플릿 \n",
    "\n",
    "> #### key : 45 rows, 2 columns\n",
    "> - 20 지역의 관측소와, 같은 지역에 위치한 월마트 매장 45곳을 레이블링한 표  \n",
    "\n",
    "> #### weather : 20517 rows, 20 columns\n",
    "> - 2012년 1월 1일 ~ 2014년 10월 31일 사이 20지역의 날씨 데이터  \n",
    "> - 온도 : Fahrenheit\n",
    "- 풍속 : mph\n",
    "- `snowfall`, `preciptotal` : inch  \n",
    "- M : Missing \n",
    "- T : Trace ( 땅이 젖을 정도로만 적게 측정 됨 )  \n",
    "\n",
    ">- **Weather Data 각 Columns의 정의**\n",
    "    - date : 날짜\n",
    "    - tmax : 최대 온도\n",
    "    - tmin : 최저 온도\n",
    "    - depart : 과거 30년 동안의 최대온도의 평균과 `tmax`값의 차\n",
    "    - dewpoint : 평균 이슬점\n",
    "    - wetbulb : 평균 습도\n",
    "    - heat : 난방 지수 (65 - `avg`) 1 ~ 6월 적용\n",
    "    - cool : 냉방 지수 (`tavg` - 65) 7 ~ 12월 적용\n",
    "    - sunrise : 일출 시간\n",
    "    - sunset : 일몰 시간 \n",
    "    - codesum : 특이 날씨 코드\n",
    "        - +FC : TORNADO/WATERSPOUT\n",
    "        - FC : FUNNEL CLOUD\n",
    "        - TS : THUNDERSTORM\n",
    "        - GR : HAIL\n",
    "        - RA : RAIN\n",
    "        - DZ : DRIZZLE\n",
    "        - SN : SNOW\n",
    "        - SG : SNOW GRAINS\n",
    "        - GS : SMALL HAIL &/OR SNOW PELLETS\n",
    "        - PL : ICE PELLETS\n",
    "        - IC : ICE CRYSTALS\n",
    "        - FG+: HEAVY FOG (FG & LE.25 MILES VISIBILITY)\n",
    "        - FG : FOG\n",
    "        - BR : MIST\n",
    "        - UP : UNKNOWN PRECIPITATION\n",
    "        - HZ : HAZE\n",
    "        - FU : SMOKE\n",
    "        - VA : VOLCANIC ASH\n",
    "        - DU : WIDESPREAD DUST\n",
    "        - DS : DUSTSTORM\n",
    "        - PO : SAND/DUST WHIRLS\n",
    "        - SA : SAND\n",
    "        - SS : SANDSTORM\n",
    "        - PY : SPRAY\n",
    "        - SQ : SQUALL\n",
    "        - DR : LOW DRIFTING\n",
    "        - SH : SHOWER\n",
    "        - FZ : FREEZING\n",
    "        - MI : SHALLOW\n",
    "        - PR : PARTIAL\n",
    "        - BC : PATCHES\n",
    "        - BL : BLOWING\n",
    "        - VC : VICINITY\n",
    "        - (-) : LIGHT\n",
    "        - (+) : HEAVY\n",
    "        - 표기가 안 되어 있다면 : moderate weather\n",
    "    - snowfall : 눈이 쌓인 정도 (inches)\n",
    "    - precipitotal : 24시간 기준 강수량 (inches)\n",
    "    - stnpressure : 평균 기압\n",
    "    - sealevel : 해수면 압력\n",
    "    - resultspeed : 합성 풍속 (mph)\n",
    "    - resultdir : 합성 풍향 (10도씩) \n",
    "    - avgspeed : 평균 풍속 (mph)\n",
    "\n",
    "        \n",
    "\n",
    "### (3) : Evaluation\n",
    "> - 예측값과 실제값의 차이를 Root-Mean-Squared-Logarithmic-Error(RMSLE)로 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "from scipy.linalg import toeplitz\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "weather = pd.read_csv('data/weather.csv')\n",
    "key = pd.read_csv('data/key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test), len(train), len(weather), len(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['store_nbr'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 35번 누락\n",
    "test['store_nbr'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 문자열이기에 nan값이 나타나지 않음\n",
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 편하게 다루기위해 test와 train을 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['logunits'] = np.log1p(train['units'])\n",
    "test['logunits']=np.nan\n",
    "test['units']=np.nan\n",
    "merged = pd.concat([train, test])\n",
    "merged = merged.sort_values(by=['date','store_nbr','item_nbr'])\n",
    "merged['date'] = pd.to_datetime(merged['date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(train['item_nbr'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['store_nbr'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "판매된 아이템만 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_nonzero_item():\n",
    "    nonzero_res = {}\n",
    "    for n in range(1, 46):\n",
    "        s1 = train[train['store_nbr']==n]\n",
    "        nonzero = s1.pivot_table(index='item_nbr', aggfunc=np.sum).reset_index()\n",
    "        nonzero = nonzero[nonzero['units']>0]\n",
    "        \n",
    "        nonzero_res[n] = nonzero['item_nbr'].values.tolist()\n",
    "        #print(n, nonzero['item_nbr'].values)\n",
    "        \n",
    "    retailed_items = []\n",
    "    for store_nbr in range(1, 46): \n",
    "        items = nonzero_res[store_nbr]\n",
    "        res = list(zip([store_nbr] * len(items), items))\n",
    "        retailed_items.extend(res)\n",
    "    \n",
    "    return pd.DataFrame(retailed_items, columns=['store_nbr','item_nbr'])\n",
    "\n",
    "retailed_items = get_nonzero_item()\n",
    "retailed_items['t']=1\n",
    "retailed_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdf = retailed_items.pivot_table(index='item_nbr',columns='store_nbr', values='t',aggfunc=np.sum)\n",
    "plt.figure(figsize=(12, 15))\n",
    "sns.heatmap(rdf)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retailed_items.pivot_table(index='item_nbr', values='t',aggfunc=np.sum).sort_values('t', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45개 매장에서 공통으로 많이 팔리는 아이템은 93, 5, 9, 45으로 분리해서 분석할 필요가 있어 보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 날씨 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 불필요한 문자열 변환\n",
    "weather2 = weather.replace('-', np.nan) \n",
    "weather2 = weather2.replace('M', np.nan) \n",
    "weather2 = weather2.replace('T', 0)\n",
    "weather2 = weather2.replace('  T', 0)\n",
    "\n",
    "# 문자열에서 날짜로 변환\n",
    "weather2.date = pd.to_datetime(weather2.date)\n",
    "\n",
    "# 문자열에서 float으로 변환\n",
    "for col in ['tmax', 'tmin', 'tavg', 'depart', 'dewpoint','wetbulb', 'heat', 'cool', 'resultdir']:\n",
    "    weather2[col] = weather2[col].astype(float)\n",
    "            \n",
    "for col in ['snowfall','preciptotal', 'stnpressure', 'sealevel', 'resultspeed','avgspeed']:\n",
    "    weather2[col] = weather2[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날씨데이터 누락값 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null값 파악\n",
    "weather2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5번 관측소만 데이터 부족\n",
    "weather2['station_nbr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날씨데이터 누락값 시계열로 처리하기 - fbprophet 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in ['tmax', 'tmin', 'tavg', 'depart', 'dewpoint',\n",
    "       'wetbulb', 'heat', 'cool', 'snowfall', 'preciptotal', 'stnpressure', 'sealevel', 'resultspeed', 'resultdir',\n",
    "       'avgspeed']:\n",
    "    \n",
    "    print(col)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for station_nbr in range(1, 21):\n",
    "        s1 = weather2[weather2.station_nbr == station_nbr]\n",
    "        plt.subplot(4, 5, station_nbr)\n",
    "        plt.plot(s1.date, s1[col])\n",
    "        plt.xticks([])\n",
    "        plt.title('station {}'.format(station_nbr))\n",
    "    plt.tight_layout(pad=1, h_pad=1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날씨 데이터의 누락값은 시계열분석으로 처리가능므로 arima 모델을 사용하여 처리한다\n",
    "5번 관측소는 데이터는 면밀히 살펴볼 필요가 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시계열 모델 만들기\n",
    "\n",
    "for col in tqdm_notebook(['tmax', 'tmin', 'tavg', 'depart', 'dewpoint',\n",
    "       'wetbulb', 'heat', 'cool', 'snowfall', 'preciptotal', 'stnpressure', 'sealevel', 'resultspeed', 'resultdir',\n",
    "       'avgspeed'], desc='col'):\n",
    "    \n",
    "    naidx_ls = []\n",
    "    predval_ls = []\n",
    "\n",
    "    for station_nbr in range(1, 21):\n",
    "        \n",
    "        # 5번 제외하고 시계열 에측 시작\n",
    "        if station_nbr == 5:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            s1 = weather2[weather2['station_nbr'] == station_nbr]\n",
    "\n",
    "            df = s1.filter(['date',col]).reset_index().rename(columns={'date':'ds',col:'y'})\n",
    "            m = Prophet(daily_seasonality=True, \n",
    "                        yearly_seasonality=True, \n",
    "                        weekly_seasonality=True, \n",
    "                        growth='linear' )\n",
    "            m.fit(df)\n",
    "\n",
    "            future = m.make_future_dataframe(periods=0) \n",
    "            forecast = m.predict(future)\n",
    "\n",
    "            yhat = forecast.yhat\n",
    "            naidx = df.y[df.y.isna()].index\n",
    "\n",
    "            dfnaidx = df[df.y.isna()]['index'].values.tolist()\n",
    "            naidx_ls.extend(dfnaidx)\n",
    "\n",
    "            predval_ls.extend(yhat[naidx])\n",
    "            #df.y[naidx] = yhat[naidx]\n",
    "            #plt.figure(figsize=(15, 3))\n",
    "            #plt.plot(df.y, label='y')\n",
    "            #plt.plot(forecast.yhat, label='yhat')\n",
    "            #plt.legend()\n",
    "            #plt.show()\n",
    "        except Exception as e:\n",
    "            print('error %s - station %d'%(col, station_nbr))\n",
    "            \n",
    "    weather2[col].loc[naidx_ls] = predval_ls\n",
    "    del predval_ls\n",
    "    del naidx_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 누락값 제거 확인\n",
    "weather2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in tqdm_notebook(['tmax', 'tmin', 'tavg', 'depart', 'dewpoint',\n",
    "       'wetbulb', 'heat', 'cool', 'snowfall', 'preciptotal', 'stnpressure', 'sealevel', 'resultspeed', 'resultdir',\n",
    "       'avgspeed']):\n",
    "    \n",
    "    print(col)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for station_nbr in range(1, 21):\n",
    "        s1 = weather2[weather2.station_nbr == station_nbr]\n",
    "        plt.subplot(4, 5, station_nbr)\n",
    "        plt.plot(s1.date, s1[col])\n",
    "        plt.xticks([])\n",
    "        plt.title('station {}'.format(station_nbr))\n",
    "    plt.tight_layout(pad=1, h_pad=1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather3 = weather2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제있는 5, 8번 제외하고 누락데이터 추정\n",
    "s5 = weather3[weather3['station_nbr'] == 5]\n",
    "s5['index'] = s5.index\n",
    "# station 8 sealevel 채우기\n",
    "s8 = weather3[weather3['station_nbr'] == 8]\n",
    "s8['index'] = s8.index\n",
    "sn5 = weather3[(weather3['station_nbr'] != 5) & (weather3['station_nbr'] != 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5번 스테이션 tmax는 다른 스테이션의 평균 값으로 대체\n",
    "avgtmp = sn5.pivot_table(index='date', aggfunc=np.average).reset_index()\n",
    "s5 = s5.merge(avgtmp, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checknan(a, b):\n",
    "    res = a\n",
    "    if np.isnan(a):\n",
    "        res = b\n",
    "    else:\n",
    "        res = a\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5['tmax'] = s5.apply(lambda row: checknan(row['tmax_x'], row['tmax_y']), axis=1)\n",
    "s5['tmin'] = s5.apply(lambda row: checknan(row['tmin_x'], row['tmin_y']), axis=1)\n",
    "s5['tavg'] = s5.apply(lambda row: checknan(row['tavg_x'], row['tavg_y']), axis=1)\n",
    "s5['dewpoint'] = s5.apply(lambda row: checknan(row['dewpoint_x'], row['dewpoint_y']), axis=1)\n",
    "s5['wetbulb'] = s5.apply(lambda row: checknan(row['wetbulb_x'], row['wetbulb_y']), axis=1)\n",
    "s5['heat'] = s5.apply(lambda row: checknan(row['heat_x'], row['heat_y']), axis=1)\n",
    "s5['cool'] = s5.apply(lambda row: checknan(row['cool_x'], row['cool_y']), axis=1) \n",
    "s5['stnpressure'] = s5.apply(lambda row: checknan(row['stnpressure_x'], row['stnpressure_y']), axis=1)\n",
    "s5['resultspeed'] = s5.apply(lambda row: checknan(row['resultspeed_x'], row['resultspeed_y']), axis=1) \n",
    "s5['resultdir'] = s5.apply(lambda row: checknan(row['resultdir_x'], row['resultdir_y']), axis=1)\n",
    "s5['avgspeed'] = s5.apply(lambda row: checknan(row['avgspeed_x'], row['avgspeed_y']), axis=1)\n",
    "s5['sealevel'] = s5.apply(lambda row: checknan(row['sealevel_x'], row['sealevel_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s5 = s5.filter(items=['index','date','tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb',\n",
    "       'heat', 'cool', 'stnpressure', 'resultspeed', 'resultdir', 'avgspeed',\n",
    "       'sealevel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb',\n",
    "       'heat', 'cool', 'stnpressure', 'resultspeed', 'resultdir', 'avgspeed',\n",
    "       'sealevel']:\n",
    "    weather3[col].loc[s5['index']] = s5[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in tqdm_notebook(['tmax', 'tmin', 'tavg', 'depart', 'dewpoint',\n",
    "       'wetbulb', 'heat', 'cool', 'snowfall', 'preciptotal', 'stnpressure', 'sealevel', 'resultspeed', 'resultdir',\n",
    "       'avgspeed']):\n",
    "    \n",
    "    print(col)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for station_nbr in range(1, 21):\n",
    "        s1 = weather3[weather3.station_nbr == station_nbr]\n",
    "        plt.subplot(4, 5, station_nbr)\n",
    "        plt.plot(s1.date, s1[col])\n",
    "        plt.xticks([])\n",
    "        plt.title('station {}'.format(station_nbr))\n",
    "    plt.tight_layout(pad=1, h_pad=1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sealevel(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather3['sealevel'].loc[s8.index] = avgtmp['sealevel'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depart, snowfall, preciptotal,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depart_from = weather3[weather3['station_nbr'].isin([2, 3, 4, 6, 11, 14, 15, 18, 19])]\n",
    "depart_from = depart_from.pivot_table(index='date', aggfunc=np.average).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['depart', 'snowfall', 'preciptotal']:\n",
    "    for station_nbr in [1, 5, 7, 8, 9, 10, 12, 13, 16, 17, 20]:\n",
    "        sdf = weather3[weather3['station_nbr'] == station_nbr]\n",
    "        sdf.insert(0, 'index', sdf.index)\n",
    "        sdf = sdf.merge(depart_from, how='left', on='date')\n",
    "\n",
    "        sdf[col] = sdf.apply(lambda row: checknan(row['{}_x'.format(col)], row['{}_y'.format(col)]), axis=1)\n",
    "\n",
    "        weather3[col].loc[sdf['index']] = sdf[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in tqdm_notebook(['depart', 'snowfall', 'preciptotal','sealevel']):\n",
    "    \n",
    "    print(col)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for station_nbr in range(1, 21):\n",
    "        s1 = weather3[weather3.station_nbr == station_nbr]\n",
    "        plt.subplot(4, 5, station_nbr)\n",
    "        plt.plot(s1.date, s1[col])\n",
    "        plt.xticks([])\n",
    "        plt.title('station {}'.format(station_nbr))\n",
    "    plt.tight_layout(pad=1, h_pad=1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunrise, sunset, codesum 을 제외한 모두 nan값 처리\n",
    "weather3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 날짜 관련 데이터 추가\n",
    "weather3['date'] = pd.to_datetime(weather3['date'])\n",
    "weather3['year'] = weather3['date'].dt.year\n",
    "weather3['month'] = weather3['date'].dt.month\n",
    "weather3['day'] = weather3['date'].dt.day\n",
    "weather3['week'] = weather3['date'].dt.week\n",
    "weather3['weekday'] = weather3['date'].dt.weekday\n",
    "weather3['quarter'] = weather3['date'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 휴일데이터 크롤링\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "def get_holidays(year):\n",
    "    response = requests.get(\"https://www.timeanddate.com/calendar/custom.html?year=\"+str(year)+\"&country=1&cols=3&df=1&hol=25\")\n",
    "    dom = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    trs = dom.select(\"table.cht.lpad tr\")\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"ds\", \"holiday\", \"lower_window\",'upper_window'])\n",
    "    for tr in trs:\n",
    "        datestr = tr.select_one(\"td:nth-of-type(1)\").text\n",
    "        date = datetime.strptime(\"{} {}\".format(year, datestr), '%Y %b %d')\n",
    "        holiday = tr.select_one(\"td:nth-of-type(2)\").text\n",
    "        df.loc[len(df)] = {\"ds\" : date, \"holiday\": holiday, \"lower_window\": 0,'upper_window':1}\n",
    "    return df\n",
    "\n",
    "def get_blackfriday(): \n",
    "    rows=[]\n",
    "    rows.append([datetime(2012, 11, 23, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2012, 11, 24, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2012, 11, 25, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2012, 11, 26, 0, 0), 'blackfriday', 0, 1])\n",
    "    \n",
    "    rows.append([datetime(2013, 11, 29, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2013, 11, 30, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2013, 12, 1, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2013, 12, 2, 0, 0), 'blackfriday', 0, 1])\n",
    "    \n",
    "    rows.append([datetime(2014, 11, 28, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2014, 11, 29, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2014, 11, 30, 0, 0), 'blackfriday', 0, 1])\n",
    "    rows.append([datetime(2014, 12, 1, 0, 0), 'blackfriday', 0, 1])\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=['ds', 'blackfriday', 'lower_window', 'upper_window'])\n",
    "\n",
    "holiday_ls = []\n",
    "for year in range(2012, 2015):\n",
    "    df = get_holidays(year)\n",
    "    holiday_ls.append(df)\n",
    "holiday_df = pd.concat(holiday_ls)\n",
    "blackfriday_df = get_blackfriday()\n",
    "     \n",
    "#holiday_df = holiday_df.sort_values(by=\"ds\").reset_index(drop=True)\n",
    "#holiday_df[\"date\"] = holiday_df[\"date\"].astype(str)\n",
    "#holiday_df[\"isbf\"] = holiday_df[\"blackfriday\"].apply(lambda x: 0 if x==0 else 1)\n",
    "#holiday_df.to_csv(\"hb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_df = pd.merge(holiday_df, blackfriday_df, how='outer', on=['ds','lower_window','upper_window'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather3 = weather3.merge(hb_df.drop(columns=['lower_window','upper_window']), how='left', left_on='date', right_on='ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather3 = weather3.drop(columns=['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather3.to_csv('data/weather_m.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather, train 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather3 = pd.read_csv('data/weather_m.csv')\n",
    "weather3['date'] = pd.to_datetime(weather3['date'])\n",
    "\n",
    "#merged = merged.drop(columns=['year','month','day','week'])\n",
    "merged = merged.merge(key, how='left', on='store_nbr')\n",
    "data = merged.merge(weather3, how='left', on=['date', 'station_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분석을 위한 데이터프레임 완성\n",
    "- 날씨, nan값처리 완료\n",
    "- 날짜\n",
    "- 휴일\n",
    "- 블랙프라이데이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_9 = data[(data['store_nbr']==1) & (data['item_nbr']==9)]\n",
    "df1_9['isholiday'] = df1_9['holiday'].apply(lambda x: 0 if str(x) == 'nan' else 1)\n",
    "df1_9['isblackfriday'] = df1_9['blackfriday'].apply(lambda x: 0 if str(x) == 'nan' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cate = ['year', 'month', 'day', 'week', 'weekday', 'quarter', 'isholiday', 'isblackfriday']\n",
    "col_num = ['tmax', 'tmin', 'tavg', 'depart', 'dewpoint', 'wetbulb', 'heat', 'cool','snowfall', 'preciptotal','stnpressure', 'sealevel', 'resultspeed', 'resultdir', 'avgspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "for idx, col in enumerate(col_num):\n",
    "    plt.subplot(3, 5, idx+1)\n",
    "    sns.regplot(df1_9[col], df1_9['logunits'])\n",
    "    plt.grid()\n",
    "    plt.yticks([])\n",
    "plt.tight_layout(pad=1, h_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날씨에 관해서 판매량과 관련있는 데이터는 찾기 힘들다.\n",
    "snowfall, preciptotal정도?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "for idx, col in enumerate(col_cate):\n",
    "    try:\n",
    "        plt.subplot(1,8, idx+1)\n",
    "        sns.regplot(df1_9[col], df1_9['logunits'])\n",
    "        plt.grid()\n",
    "        plt.yticks([])\n",
    "    except Exception as e:\n",
    "        print(col)\n",
    "plt.tight_layout(pad=1, h_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날짜에 관련해서 연도, 요일이 이 그래도 영향을 끼친다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.subplot(131)\n",
    "sns.barplot(x='weekday', y='units', data=df1_9)\n",
    "plt.subplot(132)\n",
    "sns.boxplot(x='weekday', y='units', data=df1_9)\n",
    "plt.subplot(133)\n",
    "sns.boxplot(x='weekday', y='logunits', data=df1_9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.subplot(131);sns.barplot(x='year', y='units', data=df1_9) \n",
    "plt.subplot(132);sns.boxplot(x='year', y='units', data=df1_9) \n",
    "plt.subplot(133);sns.boxplot(x='year', y='logunits', data=df1_9) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "y1 = df1_9['logunits'].values[1:]\n",
    "y2 = df1_9['logunits'].values[:-1]\n",
    "plt.subplot(1,4,1)\n",
    "sns.regplot(y1, y2) ; plt.grid(); plt.title(1)\n",
    "\n",
    "y1 = df1_9['logunits'].values[2:]\n",
    "y2 = df1_9['logunits'].values[:-2]\n",
    "plt.subplot(1,4,2)\n",
    "sns.regplot(y1, y2)  ; plt.grid(); plt.title(2)\n",
    "\n",
    "y1 = df1_9['logunits'].values[7:]\n",
    "y2 = df1_9['logunits'].values[:-7]\n",
    "plt.subplot(1,4,3)\n",
    "sns.regplot(y1, y2) ; plt.grid(); plt.title(7)\n",
    "\n",
    "y1 = df1_9['logunits'].values[14:]\n",
    "y2 = df1_9['logunits'].values[:-14]\n",
    "plt.subplot(1,4,4)\n",
    "sns.regplot(y1, y2) ; plt.grid(); plt.title(14)\n",
    "\n",
    "plt.tight_layout(pad=1, h_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1일, 2일, 7일, 14일 상관관계는 다른 날씨 변수보다 높게 나타난다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = ['tmax', 'tmin', 'tavg',\n",
    "'depart', 'dewpoint', 'wetbulb', 'heat', 'cool', 'snowfall',\n",
    "'preciptotal', 'stnpressure', 'sealevel', 'resultspeed', 'resultdir',\n",
    "'avgspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = df1_9[df1_9['units'].notna()].filter(x_col).reset_index(drop=True)\n",
    "dfy = df1_9[df1_9['units'].notna()].filter(items=['units']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_9.to_csv('data/sample_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체적인 추세 파악하기\n",
    "# 계절성이 나타나지는 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_store(n):\n",
    "    return merged[merged['store_nbr']==n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_store_item(n, item, isview=True):\n",
    "    s1 = get_store(n)\n",
    "    i9 = s1[s1['item_nbr']==item].reset_index(drop=True)\n",
    "    \n",
    "    i9['istest'] = 0\n",
    "    i9['istest'][i9['units'].isna()] = i9['units'].max()\n",
    "\n",
    "    if isview:\n",
    "        plt.figure(figsize=(20, 1))\n",
    "        plt.plot(i9['date'], i9['istest'])\n",
    "        plt.plot(i9['date'], i9['units'], c='r')\n",
    "        plt.grid()\n",
    "        plt.title('store : %d - item : %d'%(n, item))\n",
    "        plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(15, 5))\n",
    "#         for idx, year in enumerate([2012, 2013, 2014]):\n",
    "#             i92012 = i9[i9['year']==year]\n",
    "#             x = i92012['date']\n",
    "#             y = i92012['istest'] \n",
    "#             plt.subplot(3,1,idx+1)\n",
    "#             plt.plot(x, y)\n",
    "#             plt.plot(x, i92012['units'])\n",
    "#             plt.grid()\n",
    "#         plt.tight_layout(h_pad=1)\n",
    "#         plt.show()\n",
    "    return i9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(retailed_items)):\n",
    "    row = retailed_items.loc[i]\n",
    "    n = row['store_nbr']\n",
    "    item = row['item_nbr']\n",
    "    get_store_item(n, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분 추세를 갖고 있지만 계절성을 보이는 자료도 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 월별 데이터 \n",
    "col = 'units'\n",
    "for month in range(1, 13):\n",
    "    month12 = i9[(i9['month']==month) & (i9['year']==2012)]\n",
    "    month13 = i9[(i9['month']==month) & (i9['year']==2013)]\n",
    "    month14 = i9[(i9['month']==month) & (i9['year']==2014)]\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    plt.plot(month12['day'], month12[col])\n",
    "    plt.plot(month13['day'], month13[col])\n",
    "    plt.plot(month14['day'], month14[col])\n",
    "    plt.xticks([])\n",
    "    plt.title(month)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for week in range(1, 53):\n",
    "    week1 = i9[(i9['week']==week) & (i9['year']==2012)]\n",
    "\n",
    "    #plt.figure(figsize=(15, 1))\n",
    "    plt.plot(list(range(len(week1))), week1['units']) \n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
