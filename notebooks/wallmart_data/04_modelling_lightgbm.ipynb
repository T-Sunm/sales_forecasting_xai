{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee802ed-e405-4f86-985a-c6e0656c5265",
   "metadata": {},
   "source": [
    "# Part IV: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dffd0-604c-4434-9f56-9f67578d60a2",
   "metadata": {},
   "source": [
    "## Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a20043-c34e-41ec-a61f-d10c46238fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bae6ca2-7d52-4ed1-90e0-bf5dcb510dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/miniconda3/envs/sales_forecasting_ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fefc9dd-198a-4604-9ba3-c96566203eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = os.path.abspath(os.path.join(\"../..\", \"src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f3a359-c913-4b1b-8329-3a7a3c8c982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_forecast_single\n",
    "from utils.utils import flatten_prophet_predictions, weighted_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10499f54-a5e2-47e2-9460-daaeca91675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature data: (686187, 89)\n",
      "Kaggle test rows: 526917\n",
      "Train rows: 159270\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"../../data\"\n",
    "\n",
    "# 1. LOAD DATA ĐÃ PREPROCESS VÀ FEATURE ENGINEERING\n",
    "df_sales = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"data_processed/sales_data_preprocessed.csv\"),\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "df_weather = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"data_processed/weather_preprocessed.csv\"),\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "df_weather_key_store_merged = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"data_processed/weather_key_store_merged.csv\"),\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "\n",
    "# Đây là file đã có is_kaggle_test và toàn bộ features\n",
    "df_features = pd.read_feather(os.path.join(DATA_DIR,'data_processed/feature_engineered_data_89_features.feather'))\n",
    "\n",
    "print(\"Full feature data:\", df_features.shape)\n",
    "print(\"Kaggle test rows:\", df_features['is_kaggle_test'].sum())\n",
    "print(\"Train rows:\", (df_features['is_kaggle_test'] == 0).sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a351e769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'store_nbr', 'item_nbr', 'units', 'logunits', 'is_kaggle_test',\n",
       "       'station_nbr', 'tmax', 'tmin', 'tavg', 'depart', 'dewpoint', 'wetbulb',\n",
       "       'heat', 'cool', 'sunrise', 'sunset', 'snowfall', 'preciptotal',\n",
       "       'stnpressure', 'sealevel', 'resultspeed', 'resultdir', 'avgspeed',\n",
       "       'BCFG', 'BLDU', 'BLSN', 'BR', 'DU', 'DZ', 'FG', 'FG+', 'FU', 'FZDZ',\n",
       "       'FZFG', 'FZRA', 'GR', 'GS', 'HZ', 'MIFG', 'PL', 'PRFG', 'RA', 'SG',\n",
       "       'SN', 'SQ', 'TS', 'TSRA', 'TSSN', 'UP', 'VCFG', 'VCTS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_key_store_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12747917-837a-4b8a-9fc2-502deb096ea5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6afa0d-32fe-4192-b89c-00b7d9cf11e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final splits:\n",
      "  Train: (153496, 90)\n",
      "  Valid: (5774, 90)\n",
      "  Kaggle test: (526917, 90)\n"
     ]
    }
   ],
   "source": [
    "df_features['is_valid'] = 0\n",
    "mask_train = df_features['is_kaggle_test'] == 0\n",
    "cutoff_date = pd.Timestamp(\"2014-08-01\")\n",
    "df_features.loc[mask_train & (df_features['date'] >= cutoff_date), 'is_valid'] = 1\n",
    "\n",
    "# 2. Tách train/valid và kaggle test\n",
    "df_train = df_features[(df_features['is_kaggle_test'] == 0) & (df_features['is_valid'] == 0)].copy()\n",
    "df_valid = df_features[(df_features['is_kaggle_test'] == 0) & (df_features['is_valid'] == 1)].copy()\n",
    "df_kaggle_test = df_features[df_features['is_kaggle_test'] == 1].copy()\n",
    "\n",
    "print(\"Final splits:\")\n",
    "print(\"  Train:\", df_train.shape)\n",
    "print(\"  Valid:\", df_valid.shape)\n",
    "print(\"  Kaggle test:\", df_kaggle_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b12af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>logunits</th>\n",
       "      <th>is_kaggle_test</th>\n",
       "      <th>station_nbr</th>\n",
       "      <th>tmax</th>\n",
       "      <th>depart</th>\n",
       "      <th>cool</th>\n",
       "      <th>...</th>\n",
       "      <th>logunits_ewma_14d_a05</th>\n",
       "      <th>logunits_ewma_28d_a05</th>\n",
       "      <th>logunits_ewma_7d_a075</th>\n",
       "      <th>logunits_ewma_14d_a075</th>\n",
       "      <th>logunits_ewma_28d_a075</th>\n",
       "      <th>store_sum_7d</th>\n",
       "      <th>store_mean_7d</th>\n",
       "      <th>item_sum_7d</th>\n",
       "      <th>item_mean_7d</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159270</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.670772</td>\n",
       "      <td>1.238682</td>\n",
       "      <td>7.203406</td>\n",
       "      <td>1.029058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159271</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.825560</td>\n",
       "      <td>1.260794</td>\n",
       "      <td>6.510258</td>\n",
       "      <td>1.085043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159272</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.102488</td>\n",
       "      <td>1.728927</td>\n",
       "      <td>5.817111</td>\n",
       "      <td>1.163422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159273</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.648221</td>\n",
       "      <td>1.235460</td>\n",
       "      <td>5.123964</td>\n",
       "      <td>1.280991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159274</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.572480</td>\n",
       "      <td>1.367497</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>1.059351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686182</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686183</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>14</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686184</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>16</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686185</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>19</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686186</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>45</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.242453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526917 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  store_nbr  item_nbr  units  logunits  is_kaggle_test  \\\n",
       "159270 2013-04-01          2         1    NaN       NaN            True   \n",
       "159271 2013-04-01          3         1    NaN       NaN            True   \n",
       "159272 2013-04-01          6         1    NaN       NaN            True   \n",
       "159273 2013-04-01          7         1    NaN       NaN            True   \n",
       "159274 2013-04-01          8         1    NaN       NaN            True   \n",
       "...           ...        ...       ...    ...       ...             ...   \n",
       "686182 2014-10-26          1       111    NaN       NaN            True   \n",
       "686183 2014-10-26         14       111    NaN       NaN            True   \n",
       "686184 2014-10-26         16       111    NaN       NaN            True   \n",
       "686185 2014-10-26         19       111    NaN       NaN            True   \n",
       "686186 2014-10-26         45       111    NaN       NaN            True   \n",
       "\n",
       "        station_nbr  tmax    depart  cool  ...  logunits_ewma_14d_a05  \\\n",
       "159270           14  71.0  1.000000   0.0  ...                    NaN   \n",
       "159271            7  68.0  6.200000   0.0  ...                    NaN   \n",
       "159272           14  71.0  1.000000   0.0  ...                    NaN   \n",
       "159273            6  86.0  6.000000   5.0  ...                    NaN   \n",
       "159274            4  87.0  8.000000   9.0  ...                    NaN   \n",
       "...             ...   ...       ...   ...  ...                    ...   \n",
       "686182            1  58.0  5.666667   0.0  ...                    NaN   \n",
       "686183           16  58.0  7.000000   0.0  ...                    NaN   \n",
       "686184            2  53.0  2.000000   0.0  ...                    NaN   \n",
       "686185           15  57.0  4.000000   0.0  ...                    NaN   \n",
       "686186           16  58.0  7.000000   0.0  ...                    NaN   \n",
       "\n",
       "        logunits_ewma_28d_a05  logunits_ewma_7d_a075  logunits_ewma_14d_a075  \\\n",
       "159270                    NaN                    NaN                     NaN   \n",
       "159271                    NaN                    NaN                     NaN   \n",
       "159272                    NaN                    NaN                     NaN   \n",
       "159273                    NaN                    NaN                     NaN   \n",
       "159274                    NaN                    NaN                     NaN   \n",
       "...                       ...                    ...                     ...   \n",
       "686182                    NaN                    NaN                     NaN   \n",
       "686183                    NaN                    NaN                     NaN   \n",
       "686184                    NaN                    NaN                     NaN   \n",
       "686185                    NaN                    NaN                     NaN   \n",
       "686186                    NaN                    NaN                     NaN   \n",
       "\n",
       "        logunits_ewma_28d_a075  store_sum_7d  store_mean_7d  item_sum_7d  \\\n",
       "159270                     NaN      8.670772       1.238682     7.203406   \n",
       "159271                     NaN      8.825560       1.260794     6.510258   \n",
       "159272                     NaN     12.102488       1.728927     5.817111   \n",
       "159273                     NaN      8.648221       1.235460     5.123964   \n",
       "159274                     NaN      9.572480       1.367497     3.178054   \n",
       "...                        ...           ...            ...          ...   \n",
       "686182                     NaN           NaN            NaN     0.693147   \n",
       "686183                     NaN           NaN            NaN     0.693147   \n",
       "686184                     NaN           NaN            NaN     0.693147   \n",
       "686185                     NaN           NaN            NaN     0.693147   \n",
       "686186                     NaN           NaN            NaN     2.484907   \n",
       "\n",
       "        item_mean_7d  is_valid  \n",
       "159270      1.029058         0  \n",
       "159271      1.085043         0  \n",
       "159272      1.163422         0  \n",
       "159273      1.280991         0  \n",
       "159274      1.059351         0  \n",
       "...              ...       ...  \n",
       "686182      0.693147         0  \n",
       "686183      0.693147         0  \n",
       "686184      0.693147         0  \n",
       "686185      0.693147         0  \n",
       "686186      1.242453         0  \n",
       "\n",
       "[526917 rows x 90 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e5c03b-dfdb-4bdf-81e9-b811b98e50d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 153496 entries, 0 to 159249\n",
      "Data columns (total 90 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   date                    153496 non-null  datetime64[ns]\n",
      " 1   store_nbr               153496 non-null  int64         \n",
      " 2   item_nbr                153496 non-null  int64         \n",
      " 3   units                   153496 non-null  float64       \n",
      " 4   logunits                153496 non-null  float64       \n",
      " 5   is_kaggle_test          153496 non-null  bool          \n",
      " 6   station_nbr             153496 non-null  int64         \n",
      " 7   tmax                    153496 non-null  float64       \n",
      " 8   depart                  153496 non-null  float64       \n",
      " 9   cool                    153496 non-null  float64       \n",
      " 10  sunrise                 153496 non-null  float64       \n",
      " 11  sunset                  153496 non-null  float64       \n",
      " 12  snowfall                153496 non-null  float64       \n",
      " 13  preciptotal             153496 non-null  float64       \n",
      " 14  stnpressure             153496 non-null  float64       \n",
      " 15  sealevel                153496 non-null  float64       \n",
      " 16  resultspeed             153496 non-null  float64       \n",
      " 17  resultdir               153496 non-null  float64       \n",
      " 18  BCFG                    153496 non-null  int64         \n",
      " 19  BLDU                    153496 non-null  int64         \n",
      " 20  BLSN                    153496 non-null  int64         \n",
      " 21  BR                      153496 non-null  int64         \n",
      " 22  DU                      153496 non-null  int64         \n",
      " 23  DZ                      153496 non-null  int64         \n",
      " 24  FG                      153496 non-null  int64         \n",
      " 25  FG+                     153496 non-null  int64         \n",
      " 26  FU                      153496 non-null  int64         \n",
      " 27  FZDZ                    153496 non-null  int64         \n",
      " 28  FZFG                    153496 non-null  int64         \n",
      " 29  FZRA                    153496 non-null  int64         \n",
      " 30  GR                      153496 non-null  int64         \n",
      " 31  GS                      153496 non-null  int64         \n",
      " 32  HZ                      153496 non-null  int64         \n",
      " 33  MIFG                    153496 non-null  int64         \n",
      " 34  PL                      153496 non-null  int64         \n",
      " 35  PRFG                    153496 non-null  int64         \n",
      " 36  RA                      153496 non-null  int64         \n",
      " 37  SG                      153496 non-null  int64         \n",
      " 38  SN                      153496 non-null  int64         \n",
      " 39  SQ                      153496 non-null  int64         \n",
      " 40  TS                      153496 non-null  int64         \n",
      " 41  TSRA                    153496 non-null  int64         \n",
      " 42  TSSN                    153496 non-null  int64         \n",
      " 43  UP                      153496 non-null  int64         \n",
      " 44  VCFG                    153496 non-null  int64         \n",
      " 45  VCTS                    153496 non-null  int64         \n",
      " 46  year                    153496 non-null  int32         \n",
      " 47  month                   153496 non-null  int32         \n",
      " 48  day                     153496 non-null  int32         \n",
      " 49  day_of_week             153496 non-null  int32         \n",
      " 50  is_weekend              153496 non-null  int64         \n",
      " 51  season                  153496 non-null  int64         \n",
      " 52  season_Spring           153496 non-null  int64         \n",
      " 53  season_Summer           153496 non-null  int64         \n",
      " 54  season_Winter           153496 non-null  int64         \n",
      " 55  is_holiday              153496 non-null  int64         \n",
      " 56  is_blackfriday          153496 non-null  int64         \n",
      " 57  logunits_lag_1          153496 non-null  float64       \n",
      " 58  logunits_lag_2          153496 non-null  float64       \n",
      " 59  logunits_lag_3          153496 non-null  float64       \n",
      " 60  logunits_lag_4          153496 non-null  float64       \n",
      " 61  logunits_lag_5          153496 non-null  float64       \n",
      " 62  logunits_lag_6          153496 non-null  float64       \n",
      " 63  logunits_lag_7          153496 non-null  float64       \n",
      " 64  logunits_lag_14         153496 non-null  float64       \n",
      " 65  logunits_lag_21         153496 non-null  float64       \n",
      " 66  logunits_lag_28         153496 non-null  float64       \n",
      " 67  logunits_mean_7d        153496 non-null  float64       \n",
      " 68  logunits_min_7d         153496 non-null  float64       \n",
      " 69  logunits_max_7d         153496 non-null  float64       \n",
      " 70  logunits_std_7d         153496 non-null  float64       \n",
      " 71  logunits_mean_14d       153496 non-null  float64       \n",
      " 72  logunits_min_14d        153496 non-null  float64       \n",
      " 73  logunits_max_14d        153496 non-null  float64       \n",
      " 74  logunits_std_14d        153496 non-null  float64       \n",
      " 75  logunits_mean_28d       153496 non-null  float64       \n",
      " 76  logunits_min_28d        153496 non-null  float64       \n",
      " 77  logunits_max_28d        153496 non-null  float64       \n",
      " 78  logunits_std_28d        153496 non-null  float64       \n",
      " 79  logunits_ewma_7d_a05    153496 non-null  float64       \n",
      " 80  logunits_ewma_14d_a05   153496 non-null  float64       \n",
      " 81  logunits_ewma_28d_a05   153496 non-null  float64       \n",
      " 82  logunits_ewma_7d_a075   153496 non-null  float64       \n",
      " 83  logunits_ewma_14d_a075  153496 non-null  float64       \n",
      " 84  logunits_ewma_28d_a075  153496 non-null  float64       \n",
      " 85  store_sum_7d            153496 non-null  float64       \n",
      " 86  store_mean_7d           153496 non-null  float64       \n",
      " 87  item_sum_7d             153496 non-null  float64       \n",
      " 88  item_mean_7d            153496 non-null  float64       \n",
      " 89  is_valid                153496 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), float64(45), int32(4), int64(39)\n",
      "memory usage: 103.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630715f-21ce-4859-8325-6f3c8956058b",
   "metadata": {},
   "source": [
    "## Build lightgbm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2063b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (153496, 82)\n",
      "X_valid shape: (5774, 82)\n",
      "Total features: 82\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [\n",
    "    'date',           # ← Datetime không dùng trực tiếp (đã có year, month, day)\n",
    "    'units',          # ← Target gốc (data leakage!)\n",
    "    'logunits',       # ← Target đã transform (data leakage!)\n",
    "    'is_kaggle_test', # ← Flag phân chia data\n",
    "    'is_valid',       # ← Flag phân chia data\n",
    "    'station_nbr',    # ← Thông tin metadata, không cần\n",
    "    'store_nbr',\n",
    "    'item_nbr',\n",
    "]\n",
    "\n",
    "\n",
    "# Tạo X, y cho train\n",
    "X_train = df_train.drop(columns=drop_cols)\n",
    "y_train = df_train['logunits']  # Target\n",
    "\n",
    "# Tạo X, y cho valid\n",
    "X_valid = df_valid.drop(columns=drop_cols)\n",
    "y_valid = df_valid['logunits']\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"Total features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3bdc1-c273-4ee0-8f7f-923897e4cf84",
   "metadata": {},
   "source": [
    "### Build a lightgbm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea66f23-83e6-45d6-90d0-dd262986d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lightgbm_model(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Create a LightGBM model using engineered features\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating base lightgbm model...\")\n",
    "\n",
    "    # Use a time series split for validation within the training set\n",
    "    # This ensures we're always validating on future data\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    # Basic LightGBM parameters\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"n_estimators\": 100,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    # Train the model with cross-validation on training data only\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X_train):\n",
    "        X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Train the model\n",
    "        model = lgbm.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train_cv,\n",
    "            y_train_cv,\n",
    "            eval_set=[(X_val_cv, y_val_cv)],\n",
    "            # early_stopping_rounds=50,\n",
    "            # verbose=False\n",
    "        )\n",
    "\n",
    "        # Make predictions\n",
    "        preds = model.predict(X_val_cv)\n",
    "\n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_val_cv, preds)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val_cv, preds))\n",
    "        wape = weighted_absolute_percentage_error(y_val_cv, preds)\n",
    "\n",
    "        cv_scores.append((mae, rmse, wape))\n",
    "\n",
    "    # Print average scores from cross-validation\n",
    "    mae_avg, rmse_avg, wape_avg = np.mean(cv_scores, axis=0)\n",
    "    print(\n",
    "        f\"Baseline Model CV - MAE: {mae_avg:.2f}, RMSE: {rmse_avg:.2f}, WAPE: {wape_avg:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # Train a final model on all training data\n",
    "    final_model = lgbm.LGBMRegressor(**params)\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on the test set (last 3 months of 2017)\n",
    "    test_preds = final_model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, test_preds)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    test_wape = weighted_absolute_percentage_error(y_test, test_preds)\n",
    "\n",
    "    print(\n",
    "        f\"Baseline Model Test - MAE: {test_mae:.2f}, RMSE: {test_rmse:.2f}, WAPE: {test_wape:.2f}%\"\n",
    "    )\n",
    "\n",
    "    return final_model, (test_mae, test_rmse, test_wape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52819f7-c5fa-43b4-99b5-01dc13a5e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating base lightgbm model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model CV - MAE: 0.28, RMSE: 0.43, WAPE: 51.86%\n",
      "Baseline Model Test - MAE: 0.21, RMSE: 0.36, WAPE: 15.28%\n"
     ]
    }
   ],
   "source": [
    "# Gọi hàm train\n",
    "lightgbm_model, lightgbm_metrics = create_lightgbm_model(\n",
    "    X_train, y_train, X_valid, y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beff77fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model Results:\n",
      "MAE: 0.21 | RMSE: 0.36 | WAPE: 15.28%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of Prophet Model\n",
    "print(\n",
    "    f\"LightGBM Model Results:\\nMAE: {lightgbm_metrics[0]:.2f} | RMSE: {lightgbm_metrics[1]:.2f} | WAPE: {lightgbm_metrics[2]:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff1382e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved submission_lightgbm.csv (526917 rows)\n"
     ]
    }
   ],
   "source": [
    "def create_lightgbm_submission(df_kaggle_test, lightgbm_model, filename=\"submission_lightgbm.csv\"):\n",
    "    \"\"\"\n",
    "    Tạo file submission từ model LightGBM đã train.\n",
    "    - df_kaggle_test: full test dataframe (có cột is_kaggle_test, date, store_nbr, item_nbr, ...).\n",
    "    - lightgbm_model: model đã fit trên logunits.\n",
    "    - filename: tên file csv output.\n",
    "    \"\"\"\n",
    "    # 1. Lọc đúng dữ liệu cho tập Test (từ 01/04/2013 trở đi)\n",
    "    min_test_date = \"2013-04-01\"\n",
    "    df_kaggle_test_lgbm = df_kaggle_test[\n",
    "        (df_kaggle_test['is_kaggle_test'] == True) &\n",
    "        (df_kaggle_test['date'] >= min_test_date)\n",
    "    ].copy()\n",
    "\n",
    "    # 2. Tách ID columns + Features (không dùng store_nbr, item_nbr cho model)\n",
    "    id_cols = ['store_nbr', 'item_nbr', 'date']\n",
    "    drop_cols = [\n",
    "        'date', 'units', 'logunits',\n",
    "        'is_kaggle_test', 'is_valid', 'station_nbr',\n",
    "        'store_nbr', 'item_nbr'\n",
    "    ]\n",
    "\n",
    "    df_ids = df_kaggle_test_lgbm[id_cols].copy()\n",
    "    X_kaggle = df_kaggle_test_lgbm.drop(columns=drop_cols)\n",
    "\n",
    "    # 3. Predict (trên log scale) và inverse transform\n",
    "    yhat = lightgbm_model.predict(X_kaggle)\n",
    "    df_kaggle_pred = df_ids.copy()\n",
    "    df_kaggle_pred['yhat'] = yhat\n",
    "    df_kaggle_pred['units'] = np.expm1(df_kaggle_pred['yhat']).clip(lower=0)\n",
    "\n",
    "    # 4. Tạo date_str, sort và ID đúng format Kaggle\n",
    "    df_kaggle_pred['date_str'] = df_kaggle_pred['date'].dt.strftime('%Y-%m-%d')\n",
    "    df_kaggle_pred = df_kaggle_pred.sort_values(['date_str', 'store_nbr', 'item_nbr'])\n",
    "\n",
    "    df_kaggle_pred['id'] = (\n",
    "        df_kaggle_pred['store_nbr'].astype(str) + '_' +\n",
    "        df_kaggle_pred['item_nbr'].astype(str) + '_' +\n",
    "        df_kaggle_pred['date_str']\n",
    "    )\n",
    "\n",
    "    # 5. Tạo submission và lưu\n",
    "    submission = df_kaggle_pred[['id', 'units']].reset_index(drop=True)\n",
    "    submission.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"✓ Saved {filename} ({len(submission)} rows)\")\n",
    "    return submission\n",
    "\n",
    "submission_lgbm = create_lightgbm_submission(df_kaggle_test, lightgbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69bc79b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng dòng có dự đoán bán hàng: 526917\n",
      "Ví dụ 5 dòng có số liệu:\n",
      "               id      units\n",
      "0  2_1_2013-04-01   0.157354\n",
      "1  2_2_2013-04-01   0.093314\n",
      "2  2_3_2013-04-01   0.157354\n",
      "3  2_4_2013-04-01   0.093314\n",
      "4  2_5_2013-04-01  64.844115\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra nhanh: Đếm số lượng dòng dự đoán khác 0\n",
    "non_zero_preds = submission_lgbm[submission_lgbm['units'] > 0]\n",
    "print(f\"Số lượng dòng có dự đoán bán hàng: {len(non_zero_preds)}\")\n",
    "print(\"Ví dụ 5 dòng có số liệu:\")\n",
    "print(non_zero_preds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8bad5-ddbd-4091-ba03-5bcfbe412736",
   "metadata": {},
   "source": [
    "### (Optional) Fine tunning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91197807-9c05-43ad-bcd0-4040f913a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def optimize_lightgbm(X_train, y_train, X_valid, y_valid, n_trials=50, n_splits=5):\n",
    "    print(\"\\nOptimizing LightGBM model with Optuna...\")\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"verbosity\": -1,\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 127),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 20, 100),\n",
    "            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
    "            \"n_estimators\": 2000,\n",
    "        }\n",
    "\n",
    "        model = lgbm.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            callbacks=[\n",
    "                lgbm.early_stopping(stopping_rounds=100),\n",
    "                lgbm.log_evaluation(period=0),\n",
    "            ],\n",
    "        )\n",
    "        preds = model.predict(X_valid)\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "        return rmse\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params.update(\n",
    "        {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"verbosity\": -1,\n",
    "            \"n_estimators\": 2000,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"\\nBest LightGBM parameters found:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    # Train lại với cross-validation trên training data only\n",
    "    print(\"\\nTraining LightGBM with TimeSeriesSplit CV on full training data...\")\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_metrics = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(tscv.split(X_train), 1):\n",
    "        X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        cv_model = lgbm.LGBMRegressor(**best_params)\n",
    "        cv_model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[\n",
    "                lgbm.early_stopping(stopping_rounds=100),\n",
    "                lgbm.log_evaluation(period=0),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        val_pred = cv_model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, val_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "        wape = weighted_absolute_percentage_error(y_val, val_pred)\n",
    "        cv_metrics.append((mae, rmse, wape))\n",
    "        print(f\"Fold {fold}: MAE={mae:.3f}, RMSE={rmse:.3f}, WAPE={wape:.3f}\")\n",
    "\n",
    "    cv_mae, cv_rmse, cv_wape = np.mean(cv_metrics, axis=0)\n",
    "    print(f\"\\nCV mean metrics - MAE: {cv_mae:.3f}, RMSE: {cv_rmse:.3f}, WAPE: {cv_wape:.3f}\")\n",
    "\n",
    "    # Final model train trên toàn bộ X_train, y_train\n",
    "    final_model = lgbm.LGBMRegressor(**best_params)\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    # Đánh giá trên X_valid, y_valid\n",
    "    valid_preds = final_model.predict(X_valid)\n",
    "    test_mae = mean_absolute_error(y_valid, valid_preds)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_valid, valid_preds))\n",
    "    test_wape = weighted_absolute_percentage_error(y_valid, valid_preds)\n",
    "\n",
    "    print(\n",
    "        f\"\\nOptimized LightGBM Valid Metrics - \"\n",
    "        f\"MAE: {test_mae:.3f}, RMSE: {test_rmse:.3f}, WAPE: {test_wape:.3f}\"\n",
    "    )\n",
    "\n",
    "    return final_model, best_params, (test_mae, test_rmse, test_wape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a39ebd4d-bf01-4e6a-9976-e9574eb7767c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 02:59:34,720] A new study created in memory with name: no-name-7fdbd949-07b6-4ca7-b2cc-b135d65900e3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing LightGBM model with Optuna...\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 02:59:38,031] Trial 0 finished with value: 0.3630549230116088 and parameters: {'num_leaves': 77, 'learning_rate': 0.0259828792188187, 'feature_fraction': 0.7093212598323737, 'bagging_fraction': 0.9801551064948743, 'bagging_freq': 5, 'min_child_samples': 63, 'lambda_l1': 1.8589582793842138e-05, 'lambda_l2': 0.009424400802718955, 'max_depth': 14}. Best is trial 0 with value: 0.3630549230116088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's rmse: 0.363055\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 02:59:44,143] Trial 1 finished with value: 0.3615572328341624 and parameters: {'num_leaves': 121, 'learning_rate': 0.020473929640452415, 'feature_fraction': 0.78060902206764, 'bagging_fraction': 0.6757689144790431, 'bagging_freq': 2, 'min_child_samples': 97, 'lambda_l1': 0.010713722823710654, 'lambda_l2': 0.00026008895969971174, 'max_depth': 14}. Best is trial 1 with value: 0.3615572328341624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's rmse: 0.361557\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 02:59:46,123] Trial 2 finished with value: 0.36328056913972046 and parameters: {'num_leaves': 86, 'learning_rate': 0.058995553532479955, 'feature_fraction': 0.8021823155299026, 'bagging_fraction': 0.6832980655346172, 'bagging_freq': 5, 'min_child_samples': 43, 'lambda_l1': 0.8396917740579372, 'lambda_l2': 0.01933866754718752, 'max_depth': 9}. Best is trial 1 with value: 0.3615572328341624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's rmse: 0.363281\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 02:59:54,752] Trial 3 finished with value: 0.36277856938571845 and parameters: {'num_leaves': 109, 'learning_rate': 0.013682442994432904, 'feature_fraction': 0.8176196313798354, 'bagging_fraction': 0.7765928312239851, 'bagging_freq': 2, 'min_child_samples': 24, 'lambda_l1': 1.4483345532447654e-05, 'lambda_l2': 0.0002753908099323177, 'max_depth': 11}. Best is trial 1 with value: 0.3615572328341624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[692]\tvalid_0's rmse: 0.362779\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 02:59:56,104] Trial 4 finished with value: 0.3625979075636415 and parameters: {'num_leaves': 124, 'learning_rate': 0.06075723491492268, 'feature_fraction': 0.6369821610832088, 'bagging_fraction': 0.6115203687375916, 'bagging_freq': 3, 'min_child_samples': 84, 'lambda_l1': 1.938301702635449e-08, 'lambda_l2': 5.691736948157328e-06, 'max_depth': 5}. Best is trial 1 with value: 0.3615572328341624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's rmse: 0.362598\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:05,625] Trial 5 finished with value: 0.36243014644659366 and parameters: {'num_leaves': 124, 'learning_rate': 0.015575313353441386, 'feature_fraction': 0.6451380800837845, 'bagging_fraction': 0.8084904564184231, 'bagging_freq': 1, 'min_child_samples': 29, 'lambda_l1': 0.33897546098428183, 'lambda_l2': 0.00046601059523223676, 'max_depth': 15}. Best is trial 1 with value: 0.3615572328341624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[805]\tvalid_0's rmse: 0.36243\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:10,119] Trial 6 finished with value: 0.36362916263229755 and parameters: {'num_leaves': 114, 'learning_rate': 0.01148709220973824, 'feature_fraction': 0.772158977391941, 'bagging_fraction': 0.9227700994680965, 'bagging_freq': 2, 'min_child_samples': 31, 'lambda_l1': 0.00012693553686712387, 'lambda_l2': 6.640197804765116e-06, 'max_depth': 5}. Best is trial 1 with value: 0.3615572328341624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[712]\tvalid_0's rmse: 0.363629\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:13,964] Trial 7 finished with value: 0.3611063527374783 and parameters: {'num_leaves': 108, 'learning_rate': 0.033344373682626945, 'feature_fraction': 0.6407865080786973, 'bagging_fraction': 0.6562828447910182, 'bagging_freq': 4, 'min_child_samples': 37, 'lambda_l1': 0.0006976497007222383, 'lambda_l2': 3.9361535210567046e-05, 'max_depth': 10}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's rmse: 0.361106\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:16,661] Trial 8 finished with value: 0.3625390641726188 and parameters: {'num_leaves': 103, 'learning_rate': 0.06606428084524285, 'feature_fraction': 0.9582593134110342, 'bagging_fraction': 0.9961285843008185, 'bagging_freq': 2, 'min_child_samples': 93, 'lambda_l1': 3.7260017993674976e-05, 'lambda_l2': 0.00012868005018168034, 'max_depth': 11}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's rmse: 0.362539\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:18,629] Trial 9 finished with value: 0.3643326220235525 and parameters: {'num_leaves': 46, 'learning_rate': 0.04984457116394622, 'feature_fraction': 0.9754098886784252, 'bagging_fraction': 0.7033191178282958, 'bagging_freq': 4, 'min_child_samples': 84, 'lambda_l1': 2.4000796458784813e-05, 'lambda_l2': 0.7354183887338801, 'max_depth': 14}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's rmse: 0.364333\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:20,496] Trial 10 finished with value: 0.3635585715010947 and parameters: {'num_leaves': 31, 'learning_rate': 0.03577483597081568, 'feature_fraction': 0.6189271340981026, 'bagging_fraction': 0.8102902360543685, 'bagging_freq': 7, 'min_child_samples': 52, 'lambda_l1': 2.8731038313181215e-07, 'lambda_l2': 1.1077344817359359e-08, 'max_depth': 8}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's rmse: 0.363559\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:24,169] Trial 11 finished with value: 0.36255126747637045 and parameters: {'num_leaves': 90, 'learning_rate': 0.023797681231561108, 'feature_fraction': 0.868609066992212, 'bagging_fraction': 0.600949957311502, 'bagging_freq': 4, 'min_child_samples': 65, 'lambda_l1': 0.010538235148025274, 'lambda_l2': 2.8087187319128626e-07, 'max_depth': 12}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's rmse: 0.362551\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:25,331] Trial 12 finished with value: 0.364021777586503 and parameters: {'num_leaves': 67, 'learning_rate': 0.09849650313032425, 'feature_fraction': 0.7199758954469546, 'bagging_fraction': 0.6885254152167791, 'bagging_freq': 6, 'min_child_samples': 100, 'lambda_l1': 0.01642223809914047, 'lambda_l2': 1.1313173614147686e-05, 'max_depth': 8}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's rmse: 0.364022\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:30,895] Trial 13 finished with value: 0.3612385849411014 and parameters: {'num_leaves': 102, 'learning_rate': 0.020533825933478002, 'feature_fraction': 0.8928982148593947, 'bagging_fraction': 0.7418793031597601, 'bagging_freq': 3, 'min_child_samples': 42, 'lambda_l1': 0.004515079679875222, 'lambda_l2': 0.02867299706506921, 'max_depth': 13}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[430]\tvalid_0's rmse: 0.361239\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:33,796] Trial 14 finished with value: 0.36316012340609 and parameters: {'num_leaves': 99, 'learning_rate': 0.03674519667655774, 'feature_fraction': 0.9024254225577301, 'bagging_fraction': 0.7557878768111468, 'bagging_freq': 3, 'min_child_samples': 45, 'lambda_l1': 0.0012906181852220722, 'lambda_l2': 1.2773060057886827, 'max_depth': 12}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's rmse: 0.36316\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:38,332] Trial 15 finished with value: 0.36183273461929266 and parameters: {'num_leaves': 65, 'learning_rate': 0.018491548386869002, 'feature_fraction': 0.8936773799746001, 'bagging_fraction': 0.8619374617819716, 'bagging_freq': 5, 'min_child_samples': 40, 'lambda_l1': 0.0009606638894234661, 'lambda_l2': 0.05493267017028759, 'max_depth': 10}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[494]\tvalid_0's rmse: 0.361833\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:41,971] Trial 16 finished with value: 0.3625560825823329 and parameters: {'num_leaves': 98, 'learning_rate': 0.031517816139192696, 'feature_fraction': 0.7088291505493126, 'bagging_fraction': 0.7362116854016504, 'bagging_freq': 3, 'min_child_samples': 55, 'lambda_l1': 7.138566558589108, 'lambda_l2': 0.003472210604611639, 'max_depth': 7}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[396]\tvalid_0's rmse: 0.362556\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:46,124] Trial 17 finished with value: 0.3631228745279251 and parameters: {'num_leaves': 109, 'learning_rate': 0.028362360434349292, 'feature_fraction': 0.8480654666757614, 'bagging_fraction': 0.635828619644154, 'bagging_freq': 6, 'min_child_samples': 37, 'lambda_l1': 1.0446204243996682e-06, 'lambda_l2': 7.9242336377820415, 'max_depth': 11}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's rmse: 0.363123\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:49,539] Trial 18 finished with value: 0.3617686007651271 and parameters: {'num_leaves': 77, 'learning_rate': 0.043637800067745466, 'feature_fraction': 0.9346747770204351, 'bagging_fraction': 0.8508882534734588, 'bagging_freq': 4, 'min_child_samples': 21, 'lambda_l1': 0.09162605430341272, 'lambda_l2': 0.25384561786809645, 'max_depth': 13}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[302]\tvalid_0's rmse: 0.361769\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:53,600] Trial 19 finished with value: 0.36176930088027476 and parameters: {'num_leaves': 90, 'learning_rate': 0.0194103800806203, 'feature_fraction': 0.9981482235012958, 'bagging_fraction': 0.6481580094999496, 'bagging_freq': 1, 'min_child_samples': 73, 'lambda_l1': 0.001400537542276246, 'lambda_l2': 4.43499817438216e-07, 'max_depth': 10}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[412]\tvalid_0's rmse: 0.361769\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:00:58,919] Trial 20 finished with value: 0.3621863996309394 and parameters: {'num_leaves': 66, 'learning_rate': 0.010233853132544383, 'feature_fraction': 0.6729403887215181, 'bagging_fraction': 0.7266433753219819, 'bagging_freq': 3, 'min_child_samples': 48, 'lambda_l1': 7.925215972641155e-07, 'lambda_l2': 0.003202563199171405, 'max_depth': 7}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[692]\tvalid_0's rmse: 0.362186\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:03,917] Trial 21 finished with value: 0.3612308508437461 and parameters: {'num_leaves': 117, 'learning_rate': 0.02125038316173671, 'feature_fraction': 0.7575988545823413, 'bagging_fraction': 0.6581219309862364, 'bagging_freq': 2, 'min_child_samples': 35, 'lambda_l1': 0.011402279328359025, 'lambda_l2': 4.5098774191695365e-05, 'max_depth': 15}. Best is trial 7 with value: 0.3611063527374783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[323]\tvalid_0's rmse: 0.361231\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:10,860] Trial 22 finished with value: 0.36090008329374934 and parameters: {'num_leaves': 114, 'learning_rate': 0.023796106611376634, 'feature_fraction': 0.7490629957822185, 'bagging_fraction': 0.6524095699744952, 'bagging_freq': 3, 'min_child_samples': 35, 'lambda_l1': 0.05187309940512517, 'lambda_l2': 3.6921946864958816e-05, 'max_depth': 15}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[630]\tvalid_0's rmse: 0.3609\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:15,026] Trial 23 finished with value: 0.36218835161905466 and parameters: {'num_leaves': 116, 'learning_rate': 0.02528353005304744, 'feature_fraction': 0.7503496375394508, 'bagging_fraction': 0.6438128809157543, 'bagging_freq': 4, 'min_child_samples': 34, 'lambda_l1': 0.08584921716125292, 'lambda_l2': 4.2067643636214695e-05, 'max_depth': 15}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's rmse: 0.362188\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:21,493] Trial 24 finished with value: 0.3617026221208264 and parameters: {'num_leaves': 114, 'learning_rate': 0.014618214231518382, 'feature_fraction': 0.6720436724412957, 'bagging_fraction': 0.6502741478376775, 'bagging_freq': 1, 'min_child_samples': 27, 'lambda_l1': 0.00027314016891050494, 'lambda_l2': 6.534871077187692e-07, 'max_depth': 15}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[548]\tvalid_0's rmse: 0.361703\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:25,518] Trial 25 finished with value: 0.3610271956124835 and parameters: {'num_leaves': 126, 'learning_rate': 0.038989852079326384, 'feature_fraction': 0.7408020825625202, 'bagging_fraction': 0.7101184797402554, 'bagging_freq': 2, 'min_child_samples': 34, 'lambda_l1': 1.0599503277649227, 'lambda_l2': 2.2798882164949595e-06, 'max_depth': 13}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's rmse: 0.361027\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:28,855] Trial 26 finished with value: 0.36328627292457694 and parameters: {'num_leaves': 127, 'learning_rate': 0.03890690532982215, 'feature_fraction': 0.6076586741658938, 'bagging_fraction': 0.7135180525906372, 'bagging_freq': 3, 'min_child_samples': 20, 'lambda_l1': 8.110463182986217, 'lambda_l2': 1.6594786335012792e-06, 'max_depth': 13}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's rmse: 0.363286\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:31,675] Trial 27 finished with value: 0.36236632350950715 and parameters: {'num_leaves': 107, 'learning_rate': 0.047362102993548726, 'feature_fraction': 0.7299157520263273, 'bagging_fraction': 0.7753145379801019, 'bagging_freq': 4, 'min_child_samples': 57, 'lambda_l1': 1.2111890160340963, 'lambda_l2': 4.8204768346650675e-08, 'max_depth': 12}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's rmse: 0.362366\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:36,162] Trial 28 finished with value: 0.36212066677664695 and parameters: {'num_leaves': 94, 'learning_rate': 0.03134042316423371, 'feature_fraction': 0.6794440561515307, 'bagging_fraction': 0.6247481736898839, 'bagging_freq': 2, 'min_child_samples': 49, 'lambda_l1': 0.03819383268543697, 'lambda_l2': 2.2269969579330404e-05, 'max_depth': 9}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[417]\tvalid_0's rmse: 0.362121\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:37,869] Trial 29 finished with value: 0.36251307043043846 and parameters: {'num_leaves': 81, 'learning_rate': 0.08320167195658532, 'feature_fraction': 0.8294260926044086, 'bagging_fraction': 0.6764655644710256, 'bagging_freq': 5, 'min_child_samples': 62, 'lambda_l1': 0.1664692355718298, 'lambda_l2': 0.0012930964769833017, 'max_depth': 14}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's rmse: 0.362513\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:42,624] Trial 30 finished with value: 0.3615936790776776 and parameters: {'num_leaves': 119, 'learning_rate': 0.02949604336566403, 'feature_fraction': 0.6943001912781356, 'bagging_fraction': 0.7031831577598805, 'bagging_freq': 4, 'min_child_samples': 31, 'lambda_l1': 2.000900469985746, 'lambda_l2': 1.4641719342251502e-06, 'max_depth': 13}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's rmse: 0.361594\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:46,752] Trial 31 finished with value: 0.36143972184709594 and parameters: {'num_leaves': 113, 'learning_rate': 0.024597647494103356, 'feature_fraction': 0.7621542051764335, 'bagging_fraction': 0.6640902367895398, 'bagging_freq': 2, 'min_child_samples': 36, 'lambda_l1': 0.004942837092272058, 'lambda_l2': 5.722649334620695e-05, 'max_depth': 15}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's rmse: 0.36144\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:52,480] Trial 32 finished with value: 0.3618115815150675 and parameters: {'num_leaves': 120, 'learning_rate': 0.017087460748410773, 'feature_fraction': 0.7492292482761547, 'bagging_fraction': 0.6229162090415369, 'bagging_freq': 1, 'min_child_samples': 38, 'lambda_l1': 0.048676473727961765, 'lambda_l2': 3.543797995477301e-06, 'max_depth': 14}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[468]\tvalid_0's rmse: 0.361812\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:01:58,907] Trial 33 finished with value: 0.36097598841891126 and parameters: {'num_leaves': 121, 'learning_rate': 0.022519731828277396, 'feature_fraction': 0.7827255071816221, 'bagging_fraction': 0.6628425243169128, 'bagging_freq': 2, 'min_child_samples': 33, 'lambda_l1': 0.8290713089426937, 'lambda_l2': 8.152307609533312e-05, 'max_depth': 14}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[431]\tvalid_0's rmse: 0.360976\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:05,495] Trial 34 finished with value: 0.3615367954869414 and parameters: {'num_leaves': 107, 'learning_rate': 0.02273055490497307, 'feature_fraction': 0.7970830750865043, 'bagging_fraction': 0.6744520294475537, 'bagging_freq': 3, 'min_child_samples': 28, 'lambda_l1': 0.5768377990301043, 'lambda_l2': 1.0475898356576954e-07, 'max_depth': 14}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[556]\tvalid_0's rmse: 0.361537\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:09,957] Trial 35 finished with value: 0.36196377520354306 and parameters: {'num_leaves': 126, 'learning_rate': 0.027556377190584916, 'feature_fraction': 0.7939005269890476, 'bagging_fraction': 0.7005695355584345, 'bagging_freq': 2, 'min_child_samples': 25, 'lambda_l1': 2.8422678545322144, 'lambda_l2': 0.0005969313194520492, 'max_depth': 12}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's rmse: 0.361964\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:12,574] Trial 36 finished with value: 0.3615190257162424 and parameters: {'num_leaves': 119, 'learning_rate': 0.04205577496493288, 'feature_fraction': 0.8181101721737821, 'bagging_fraction': 0.6015904808647783, 'bagging_freq': 3, 'min_child_samples': 46, 'lambda_l1': 0.24416248436834287, 'lambda_l2': 0.0001560246095068447, 'max_depth': 9}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's rmse: 0.361519\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:18,899] Trial 37 finished with value: 0.3621973517527839 and parameters: {'num_leaves': 123, 'learning_rate': 0.0338006243154644, 'feature_fraction': 0.7347699171442301, 'bagging_fraction': 0.7667421767633358, 'bagging_freq': 2, 'min_child_samples': 32, 'lambda_l1': 0.9422522992865461, 'lambda_l2': 2.213234286419289e-05, 'max_depth': 13}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[407]\tvalid_0's rmse: 0.362197\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:21,043] Trial 38 finished with value: 0.3630862512108347 and parameters: {'num_leaves': 110, 'learning_rate': 0.05236626826635344, 'feature_fraction': 0.641008619636249, 'bagging_fraction': 0.6734876590726178, 'bagging_freq': 1, 'min_child_samples': 42, 'lambda_l1': 5.427011582299254e-06, 'lambda_l2': 3.356114324869136e-06, 'max_depth': 14}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's rmse: 0.363086\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:28,463] Trial 39 finished with value: 0.36232590790683267 and parameters: {'num_leaves': 104, 'learning_rate': 0.012618036118267926, 'feature_fraction': 0.7796049823914875, 'bagging_fraction': 0.7184468836156424, 'bagging_freq': 3, 'min_child_samples': 24, 'lambda_l1': 0.301089938543503, 'lambda_l2': 0.0001328863796826892, 'max_depth': 11}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[626]\tvalid_0's rmse: 0.362326\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:32,974] Trial 40 finished with value: 0.36266697684499616 and parameters: {'num_leaves': 127, 'learning_rate': 0.026261348195553157, 'feature_fraction': 0.6552543041854558, 'bagging_fraction': 0.7962733672962677, 'bagging_freq': 5, 'min_child_samples': 51, 'lambda_l1': 3.7919989968586063, 'lambda_l2': 0.0006336125637053788, 'max_depth': 15}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's rmse: 0.362667\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:38,457] Trial 41 finished with value: 0.3618097391672954 and parameters: {'num_leaves': 117, 'learning_rate': 0.01667106504528372, 'feature_fraction': 0.762669076446297, 'bagging_fraction': 0.6499124828642819, 'bagging_freq': 2, 'min_child_samples': 35, 'lambda_l1': 0.023259243804559158, 'lambda_l2': 4.063478034268146e-05, 'max_depth': 15}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[354]\tvalid_0's rmse: 0.36181\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:43,397] Trial 42 finished with value: 0.3630438796049234 and parameters: {'num_leaves': 113, 'learning_rate': 0.02235920364403801, 'feature_fraction': 0.7026734800471439, 'bagging_fraction': 0.6220852639195508, 'bagging_freq': 2, 'min_child_samples': 40, 'lambda_l1': 0.004424558429605759, 'lambda_l2': 1.3157669055843239e-05, 'max_depth': 15}. Best is trial 22 with value: 0.36090008329374934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's rmse: 0.363044\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:51,518] Trial 43 finished with value: 0.36005172199682944 and parameters: {'num_leaves': 123, 'learning_rate': 0.020540826929007872, 'feature_fraction': 0.7406470795364658, 'bagging_fraction': 0.659857938777664, 'bagging_freq': 2, 'min_child_samples': 30, 'lambda_l1': 7.219915314715502e-05, 'lambda_l2': 8.840538888681772e-05, 'max_depth': 14}. Best is trial 43 with value: 0.36005172199682944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[608]\tvalid_0's rmse: 0.360052\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:02:54,756] Trial 44 finished with value: 0.3629933569384584 and parameters: {'num_leaves': 124, 'learning_rate': 0.033424830781185404, 'feature_fraction': 0.7361091120702652, 'bagging_fraction': 0.6935857431094157, 'bagging_freq': 1, 'min_child_samples': 31, 'lambda_l1': 0.00013811027975574574, 'lambda_l2': 0.00023708453096949462, 'max_depth': 14}. Best is trial 43 with value: 0.36005172199682944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's rmse: 0.362993\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:03:00,075] Trial 45 finished with value: 0.3624021687424954 and parameters: {'num_leaves': 121, 'learning_rate': 0.017813759925952168, 'feature_fraction': 0.7802428721391709, 'bagging_fraction': 0.6862896655837218, 'bagging_freq': 3, 'min_child_samples': 67, 'lambda_l1': 7.700389678967162e-06, 'lambda_l2': 9.860466202396605e-06, 'max_depth': 11}. Best is trial 43 with value: 0.36005172199682944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's rmse: 0.362402\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:03:02,466] Trial 46 finished with value: 0.3634035941882934 and parameters: {'num_leaves': 51, 'learning_rate': 0.039929919973027736, 'feature_fraction': 0.8191667179547297, 'bagging_fraction': 0.6333651322980525, 'bagging_freq': 2, 'min_child_samples': 28, 'lambda_l1': 4.996357588059291e-05, 'lambda_l2': 8.911622734933179e-05, 'max_depth': 14}. Best is trial 43 with value: 0.36005172199682944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's rmse: 0.363404\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:03:04,793] Trial 47 finished with value: 0.3631626061277768 and parameters: {'num_leaves': 122, 'learning_rate': 0.06726058435693845, 'feature_fraction': 0.7213033941100279, 'bagging_fraction': 0.7504442619083443, 'bagging_freq': 4, 'min_child_samples': 44, 'lambda_l1': 1.2938415092984898e-08, 'lambda_l2': 0.0018114126607868995, 'max_depth': 12}. Best is trial 43 with value: 0.36005172199682944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's rmse: 0.363163\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:03:11,635] Trial 48 finished with value: 0.3618153590224336 and parameters: {'num_leaves': 112, 'learning_rate': 0.01532400294511798, 'feature_fraction': 0.8521334874265294, 'bagging_fraction': 0.6637310965862802, 'bagging_freq': 2, 'min_child_samples': 22, 'lambda_l1': 6.116163218650899e-05, 'lambda_l2': 0.0003787470803500018, 'max_depth': 9}. Best is trial 43 with value: 0.36005172199682944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[591]\tvalid_0's rmse: 0.361815\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 03:03:14,865] Trial 49 finished with value: 0.36294242983663705 and parameters: {'num_leaves': 105, 'learning_rate': 0.02986632092546155, 'feature_fraction': 0.6913768600480269, 'bagging_fraction': 0.949165639892339, 'bagging_freq': 1, 'min_child_samples': 39, 'lambda_l1': 0.0006350201862025008, 'lambda_l2': 5.335423064802711e-06, 'max_depth': 10}. Best is trial 43 with value: 0.36005172199682944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's rmse: 0.362942\n",
      "\n",
      "Best LightGBM parameters found:\n",
      "  num_leaves: 123\n",
      "  learning_rate: 0.020540826929007872\n",
      "  feature_fraction: 0.7406470795364658\n",
      "  bagging_fraction: 0.659857938777664\n",
      "  bagging_freq: 2\n",
      "  min_child_samples: 30\n",
      "  lambda_l1: 7.219915314715502e-05\n",
      "  lambda_l2: 8.840538888681772e-05\n",
      "  max_depth: 14\n",
      "  objective: regression\n",
      "  metric: rmse\n",
      "  boosting_type: gbdt\n",
      "  verbosity: -1\n",
      "  n_estimators: 2000\n",
      "\n",
      "Training LightGBM with TimeSeriesSplit CV on full training data...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's rmse: 0.506119\n",
      "Fold 1: MAE=0.367, RMSE=0.506, WAPE=23.192\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[428]\tvalid_0's rmse: 0.303702\n",
      "Fold 2: MAE=0.202, RMSE=0.304, WAPE=6.206\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's rmse: 0.450726\n",
      "Fold 3: MAE=0.304, RMSE=0.451, WAPE=40.260\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's rmse: 0.613709\n",
      "Fold 4: MAE=0.427, RMSE=0.614, WAPE=93.296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[431]\tvalid_0's rmse: 0.25942\n",
      "Fold 5: MAE=0.100, RMSE=0.259, WAPE=86.734\n",
      "\n",
      "CV mean metrics - MAE: 0.280, RMSE: 0.427, WAPE: 49.938\n",
      "\n",
      "Optimized LightGBM Valid Metrics - MAE: 0.200, RMSE: 0.362, WAPE: 14.708\n"
     ]
    }
   ],
   "source": [
    "optimized_model, best_params, optimized_metrics = optimize_lightgbm(\n",
    "    X_train, y_train, X_valid, y_valid, n_trials=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "970ed2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved submission_lightgbm.csv (526917 rows)\n"
     ]
    }
   ],
   "source": [
    "submission_lgbm = create_lightgbm_submission(df_kaggle_test, optimized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dcb0bd-8977-4f88-88bf-3678ec5ab50b",
   "metadata": {},
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7306f426-a791-4612-9348-d3b4ed663e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, data):\n",
    "    \"\"\"\n",
    "    Evaluate the model performance on the test set (last 3 months of 2017)\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluating model performance on test set...\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_mae = mean_absolute_error(y_test, test_preds)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    test_wape = weighted_absolute_percentage_error(y_test, test_preds)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Final Model Test Evaluation:\")\n",
    "    print(f\"    MAE: {test_mae:.2f}\")\n",
    "    print(f\"    RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"    WAPE: {test_wape:.2f}%\")\n",
    "\n",
    "    # Analyze errors by time period (month)\n",
    "    test_results = data[data[\"is_test\"]].copy()\n",
    "    test_results[\"prediction\"] = test_preds\n",
    "    test_results[\"error\"] = test_results[\"sales\"] - test_results[\"prediction\"]\n",
    "    test_results[\"abs_error\"] = np.abs(test_results[\"error\"])\n",
    "    test_results[\"month_name\"] = test_results[\"date\"].dt.strftime(\"%B\")\n",
    "\n",
    "    # Summarize errors by month\n",
    "    monthly_errors = (\n",
    "        test_results.groupby(\"month_name\")\n",
    "        .agg({\"abs_error\": \"mean\", \"error\": \"mean\", \"sales\": \"mean\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    monthly_errors[\"error_pct\"] = (\n",
    "        100 * monthly_errors[\"abs_error\"] / monthly_errors[\"sales\"]\n",
    "    )\n",
    "\n",
    "    print(\"\\nError Analysis by Month:\")\n",
    "    print(\n",
    "        monthly_errors[[\"month_name\", \"abs_error\", \"error_pct\"]].to_string(index=False)\n",
    "    )\n",
    "\n",
    "    # Store results for visualization\n",
    "    # Include month and store information for granular analysis\n",
    "    test_results[\"year_month\"] = test_results[\"date\"].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, test_preds, alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], \"r--\")\n",
    "    plt.title(\"Actual vs Predicted Sales (Test Set)\")\n",
    "    plt.xlabel(\"Actual Sales\")\n",
    "    plt.ylabel(\"Predicted Sales\")\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('actual_vs_predicted_test.png')\n",
    "\n",
    "    # Plot error distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(test_results[\"error\"], kde=True)\n",
    "    plt.title(\"Error Distribution\")\n",
    "    plt.xlabel(\"Prediction Error\")\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('error_distribution.png')\n",
    "\n",
    "    return test_mae, test_rmse, test_wape, test_preds, y_test, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b19bcf0-9d6a-4218-bba3-129fada6026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet Model Results:\n",
    "# MAE: 9.03 | RMSE: 11.86 | WAPE: 29.13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acbf2b3c-f81b-4746-90cc-8c4a8088a268",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the lightgbm model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m test_mae, test_rmse, test_smape, test_preds, y_test_values, test_results \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 3\u001b[0m     evaluate_model(lightgbm_model, \u001b[43mX_test\u001b[49m, y_test, df_features)\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the lightgbm model\n",
    "test_mae, test_rmse, test_smape, test_preds, y_test_values, test_results = (\n",
    "    evaluate_model(lightgbm_model, X_test, y_test, df_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e343dda-bec5-4525-91cc-a81ac25229d0",
   "metadata": {},
   "source": [
    "## Save trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8505cb-07cb-4175-9e04-5b4674befac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, X_train, feature_names, output_dir=\"../models\"):\n",
    "    \"\"\"\n",
    "    Save the trained model and related artifacts for API use\n",
    "\n",
    "    Args:\n",
    "        model: Trained model (e.g., LightGBM model)\n",
    "        feature_names: List of feature names\n",
    "        output_dir: Directory to save model artifacts\n",
    "    \"\"\"\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = os.path.join(output_dir, \"sales_forecast_model.pkl\")\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Create and save feature statistics\n",
    "    feature_stats = {\n",
    "        \"model_version\": \"1.0.0\",\n",
    "        \"last_trained\": pd.Timestamp.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"required_columns\": list(feature_names),\n",
    "        \"column_order\": list(feature_names),\n",
    "        \"default_values\": {},\n",
    "        \"temperature_bins\": [-np.inf, 20, 25, 30, np.inf],\n",
    "        \"temperature_labels\": [\"Cold\", \"Cool\", \"Warm\", \"Hot\"],\n",
    "        \"humidity_bins\": [-np.inf, 60, 75, np.inf],\n",
    "        \"humidity_labels\": [\"Low\", \"Medium\", \"High\"],\n",
    "    }\n",
    "\n",
    "    # Add default values for date features\n",
    "    feature_stats[\"default_values\"] = {\n",
    "        \"year\": 2017,\n",
    "        \"month\": 11,\n",
    "        \"day\": 15,\n",
    "        \"day_of_week\": 2,\n",
    "        \"is_weekend\": 0,\n",
    "        \"quarter\": 4,\n",
    "        \"is_holiday\": 0,\n",
    "    }\n",
    "\n",
    "    # Save feature stats\n",
    "    stats_path = os.path.join(output_dir, \"feature_stats.json\")\n",
    "    with open(stats_path, \"w\") as f:\n",
    "        json.dump(feature_stats, f, indent=4)\n",
    "    print(f\"Feature statistics saved to {stats_path}\")\n",
    "\n",
    "    print(f\"All model artifacts saved successfully to {output_dir}/\")\n",
    "\n",
    "    return model_path, stats_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2cd1b-6d74-435c-be7c-d0ac999020d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/sales_forecast_model.pkl\n",
      "Feature statistics saved to ../models/feature_stats.json\n",
      "All model artifacts saved successfully to ../models/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/sales_forecast_model.pkl', '../models/feature_stats.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "save_model(\n",
    "    model=optimized_model,\n",
    "    X_train=X_train,\n",
    "    feature_names=X_train.columns,\n",
    "    output_dir='../models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5cc83-1c5b-4ab3-83af-cd3a6c3f00fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales_forecasting_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
